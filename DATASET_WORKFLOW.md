# ğŸ” Guide du Workflow de Validation des Datasets

Ce guide explique comment utiliser le nouveau systÃ¨me de validation des datasets pour TradePulse ML avec contrÃ´le qualitÃ© automatique.

## ğŸ¯ Vue d'ensemble du workflow

```mermaid
graph TD
    A[ğŸ“ Nouveau dataset] --> B{Mode d'ajout}
    B -->|Direct push| C[ğŸ” Quality Gate]
    B -->|Pull Request| D[ğŸ” PR Validation]
    
    C -->|âœ… Valid| E[ğŸ¤– Auto Fine-tuning]
    C -->|âŒ Invalid| F[ğŸš« Blocked]
    
    D -->|âœ… Valid| G[âœ¨ Merge to main]
    D -->|âŒ Invalid| H[ğŸ”§ Fix required]
    
    G --> E
    H --> I[ğŸ“ Corrections]
    I --> D
    
    E --> J[ğŸ‰ Model ready]
```

## ğŸ“‹ Ã‰tapes du processus

### 1. ğŸ“Š PrÃ©parer votre dataset

Votre dataset doit respecter le format suivant :

#### Format CSV (recommandÃ©)
```csv
text,label
"Apple reported strong earnings beating analyst expectations...",positive
"Market volatility increased amid economic uncertainty...",negative  
"Oil prices remained stable following OPEC meeting...",neutral
```

#### Format JSON (alternatif)
```json
[
  {
    "text": "Apple reported strong earnings...",
    "label": "positive"
  },
  {
    "text": "Market volatility increased...", 
    "label": "negative"
  }
]
```

#### ğŸ“ CritÃ¨res de qualitÃ©
- **Labels valides** : `positive`, `negative`, `neutral` (case-insensitive)
- **Colonnes requises** : `text` et `label`
- **Pas de doublons** dans les textes
- **Longueur recommandÃ©e** : 20-512 caractÃ¨res par texte
- **Distribution Ã©quilibrÃ©e** : Ã©viter plus de 70% d'une seule classe

### 2. ğŸ” Validation automatique

#### Option A : Validation via Pull Request (RecommandÃ©e)

1. **CrÃ©er une branche** :
   ```bash
   git checkout -b feature/dataset-20250706
   ```

2. **Ajouter votre dataset** :
   ```bash
   cp mon_dataset.csv datasets/financial_news_20250706.csv
   git add datasets/financial_news_20250706.csv
   git commit -m "Add financial news dataset for Q4 training"
   git push origin feature/dataset-20250706
   ```

3. **CrÃ©er une Pull Request** :
   - GitHub dÃ©clenchera automatiquement le **Dataset Quality Gate**
   - Validation complÃ¨te avec rapport dÃ©taillÃ©
   - Commentaire automatique sur la PR avec rÃ©sultats

4. **RÃ©vision et merge** :
   - Si âœ… validation OK â†’ Merge possible
   - Si âŒ validation KO â†’ Corrections requises

#### Option B : Push direct (validation simple)

```bash
git add datasets/mon_dataset.csv
git commit -m "Add new training dataset"  
git push origin main
```
â†’ Quality Gate se dÃ©clenche mais training aussi (plus risquÃ©)

### 3. ğŸ¤– Fine-tuning automatique

AprÃ¨s validation rÃ©ussie, le fine-tuning se lance automatiquement avec :

- **Dataset** : Le dernier CSV validÃ©
- **ModÃ¨le** : `yiyanghkust/finbert-tone` (par dÃ©faut)
- **Configuration** : 3 epochs, learning rate 2e-5
- **Sortie** : Model dans `models/finbert-YYYYMMDD_HHMMSS/`

## ğŸ› ï¸ Utilisation avancÃ©e

### Validation manuelle d'un dataset

```bash
# Local
python scripts/validate_dataset.py datasets/mon_dataset.csv

# GitHub Actions (manuel)
# Aller dans Actions â†’ Dataset Quality Gate â†’ Run workflow
# SpÃ©cifier : datasets/mon_dataset.csv
```

### Fine-tuning avec paramÃ¨tres personnalisÃ©s

1. **Actions** â†’ **TradePulse FinBERT Fine-tuning** â†’ **Run workflow**
2. Configurer :
   - **Dataset** : `auto-latest` ou nom spÃ©cifique
   - **Model** : FinBERT variant
   - **Epochs** : 1-10
   - **Learning rate** : 1e-5 Ã  5e-5
   - **Push to Hub** : true/false

### Validation locale avant push

```bash
# Installer les dÃ©pendances
pip install pandas>=2.0.0

# Valider votre dataset
python scripts/validate_dataset.py datasets/mon_dataset.csv

# Si tout OK
git add datasets/mon_dataset.csv
git commit -m "Add validated dataset"
git push
```

## ğŸ“Š Rapport de validation

Le script de validation gÃ©nÃ¨re un rapport complet :

```
ğŸ” RAPPORT DE VALIDATION DATASET
==================================================

ğŸ“Š STATISTIQUES:
  Total Ã©chantillons: 20
  Longueur moyenne: 156.4 caractÃ¨res
  Longueur min/max: 89/245
  Doublons: 0

ğŸ“ˆ DISTRIBUTION DES LABELS:
  positive: 8 (40.0%)
  negative: 6 (30.0%)
  neutral: 6 (30.0%)

âœ… VALIDATION RÃ‰USSIE
```

### Types d'erreurs dÃ©tectÃ©es

| Erreur | Description | Solution |
|--------|-------------|----------|
| âŒ Colonnes incorrectes | Manque `text` ou `label` | Renommer les colonnes |
| âŒ Labels invalides | Autre que positive/negative/neutral | Corriger les labels |
| âŒ Textes manquants | Cellules vides | Supprimer ou remplir |
| âš ï¸ Textes dupliquÃ©s | MÃªme contenu rÃ©pÃ©tÃ© | DÃ©dupliquer |
| âš ï¸ Classe dÃ©sÃ©quilibrÃ©e | >70% d'une classe | Ã‰quilibrer ou accepter |
| âš ï¸ Textes trop longs | >512 caractÃ¨res | Tronquer ou accepter |

## ğŸ”§ DÃ©pannage

### Validation Ã©choue
```bash
# Voir les dÃ©tails de l'erreur
python scripts/validate_dataset.py datasets/mon_dataset.csv

# VÃ©rifier le format
head -5 datasets/mon_dataset.csv

# VÃ©rifier l'encodage  
file datasets/mon_dataset.csv
```

### Training ne se dÃ©clenche pas
1. VÃ©rifier que la validation a rÃ©ussi
2. Aller dans **Actions** â†’ vÃ©rifier les logs du Quality Gate
3. Si push direct, vÃ©rifier le chemin du fichier `datasets/*.csv`

### Dataset pas dÃ©tectÃ©
```bash
# VÃ©rifier la structure
ls -la datasets/

# Le fichier doit Ãªtre dans datasets/ avec extension .csv ou .json
# Pas dans un sous-dossier (datasets/raw/, datasets/labeled/)
```

## ğŸ’¡ Bonnes pratiques

### ğŸ“ Nommage des datasets
```
datasets/
â”œâ”€â”€ financial_news_YYYYMMDD.csv     # Dataset principal par date
â”œâ”€â”€ crypto_sentiment_v2.csv          # Dataset spÃ©cialisÃ© avec version
â”œâ”€â”€ earnings_calls_Q4_2024.csv      # Dataset par pÃ©riode
â””â”€â”€ mixed_sources_validated.csv     # Dataset multi-sources
```

### ğŸ·ï¸ Labels cohÃ©rents
- **positive** : Hausse, bonne nouvelle, croissance, succÃ¨s
- **negative** : Baisse, mauvaise nouvelle, crise, Ã©chec  
- **neutral** : StabilitÃ©, information factuelle, status quo

### ğŸ“Š Taille recommandÃ©e
- **Minimum** : 50 Ã©chantillons (10+ par classe)
- **Optimal** : 200-1000 Ã©chantillons
- **Maximum** : Pas de limite technique

### ğŸ”„ Workflow type
1. Collecter les donnÃ©es brutes â†’ `datasets/raw/`
2. Labelliser/nettoyer â†’ `datasets/labeled/`
3. CrÃ©er branch + PR avec dataset final â†’ `datasets/`
4. Validation automatique â†’ corrections si nÃ©cessaire
5. Merge â†’ Fine-tuning automatique
6. Model prÃªt ! ğŸ‰

## ğŸš€ Exemples rapides

### Ajouter un dataset rapidement
```bash
# 1. CrÃ©er le CSV
echo 'text,label' > datasets/test_20250706.csv
echo '"Tesla stock rose 5%",positive' >> datasets/test_20250706.csv

# 2. Valider
python scripts/validate_dataset.py datasets/test_20250706.csv

# 3. Push
git add datasets/test_20250706.csv
git commit -m "Add test dataset" 
git push
```

### Corriger un dataset invalide
```bash
# Voir l'erreur
python scripts/validate_dataset.py datasets/problematic.csv

# Ã‰diter le fichier
nano datasets/problematic.csv

# Re-valider
python scripts/validate_dataset.py datasets/problematic.csv

# Push correction
git add datasets/problematic.csv
git commit -m "Fix dataset validation issues"
git push
```

---

## ğŸ“ Support

- ğŸ› **Issues** : Ouvrir une issue GitHub
- ğŸ“‹ **Logs** : Consulter Actions â†’ Job logs
- ğŸ“– **Documentation** : Ce guide + README.md
- ğŸ” **Validation** : `python scripts/validate_dataset.py --help`

**Happy training! ğŸ¤–âœ¨**
