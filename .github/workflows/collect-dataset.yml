name: ğŸ“° Daily News Dataset Collection

on:
  # Collecte quotidienne Ã  06:00 UTC (08:00 CET)
  schedule:
    - cron: '0 6 * * *'
  
  # Collecte manuelle
  workflow_dispatch:
    inputs:
      source:
        description: 'Source de donnÃ©es'
        required: true
        default: 'placeholder'
        type: choice
        options:
          - 'placeholder'
          - 'rss'
          - 'newsapi'
      
      count:
        description: 'Nombre d\'Ã©chantillons Ã  collecter'
        required: true
        default: '25'
        type: string
      
      force_commit:
        description: 'Forcer le commit mÃªme si aucun changement'
        required: false
        default: false
        type: boolean

jobs:
  collect-and-commit:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    outputs:
      dataset-created: ${{ steps.collect.outputs.dataset-created }}
      dataset-path: ${{ steps.collect.outputs.dataset-path }}
      sample-count: ${{ steps.collect.outputs.sample-count }}
    
    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 1
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: ğŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'

    - name: ğŸ“¦ Install Dependencies
      run: |
        python -m pip install --upgrade pip
        
        # DÃ©pendances de base
        pip install pandas>=2.0.0
        
        # DÃ©pendances optionnelles pour collecte RSS/NewsAPI
        pip install feedparser requests || echo "Optional dependencies failed, will use placeholder"
        
        echo "âœ… Dependencies installed"

    - name: ğŸ“° Collect News Dataset
      id: collect
      env:
        NEWSAPI_KEY: ${{ secrets.NEWSAPI_KEY }}
      run: |
        set -euo pipefail
        
        # DÃ©terminer les paramÃ¨tres selon le mode de dÃ©clenchement
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          SOURCE="${{ github.event.inputs.source }}"
          COUNT="${{ github.event.inputs.count }}"
          FORCE_COMMIT="${{ github.event.inputs.force_commit }}"
        else
          # DÃ©clenchement automatique (cron)
          SOURCE="placeholder"  # Changer en "rss" quand prÃªt
          COUNT="25"
          FORCE_COMMIT="false"
        fi
        
        echo "ğŸ”§ Configuration:"
        echo "  Source: $SOURCE"
        echo "  Count: $COUNT"
        echo "  Force commit: $FORCE_COMMIT"
        
        # ExÃ©cuter le collecteur
        echo "ğŸ“° Collecte des actualitÃ©s financiÃ¨res..."
        
        if python scripts/collect_news.py --source "$SOURCE" --count "$COUNT"; then
          echo "âœ… Collecte rÃ©ussie"
          
          # DÃ©terminer le fichier crÃ©Ã©
          TODAY=$(date -u '+%Y%m%d')
          DATASET_FILE="datasets/news_${TODAY}.csv"
          
          if [ -f "$DATASET_FILE" ]; then
            SAMPLE_COUNT=$(tail -n +2 "$DATASET_FILE" | wc -l)
            echo "ğŸ“Š Dataset crÃ©Ã©: $DATASET_FILE ($SAMPLE_COUNT Ã©chantillons)"
            
            echo "dataset-created=true" >> $GITHUB_OUTPUT
            echo "dataset-path=$DATASET_FILE" >> $GITHUB_OUTPUT
            echo "sample-count=$SAMPLE_COUNT" >> $GITHUB_OUTPUT
          else
            echo "âŒ Dataset non trouvÃ© aprÃ¨s collecte"
            exit 1
          fi
        else
          echo "âŒ Ã‰chec de la collecte"
          exit 1
        fi

    - name: ğŸ” Validate Dataset Quality
      if: steps.collect.outputs.dataset-created == 'true'
      run: |
        DATASET_PATH="${{ steps.collect.outputs.dataset-path }}"
        
        echo "ğŸ” Validation du dataset: $DATASET_PATH"
        
        # Utiliser notre script de validation si disponible
        if [ -f "scripts/validate_dataset.py" ]; then
          if python scripts/validate_dataset.py "$DATASET_PATH"; then
            echo "âœ… Validation rÃ©ussie"
          else
            echo "âŒ Dataset invalide - arrÃªt du processus"
            echo "ğŸ’¡ VÃ©rifiez la qualitÃ© des donnÃ©es collectÃ©es"
            exit 1
          fi
        else
          echo "âš ï¸ Script de validation non trouvÃ©, validation basique..."
          
          # Validation basique
          if [ ! -s "$DATASET_PATH" ]; then
            echo "âŒ Dataset vide"
            exit 1
          fi
          
          # VÃ©rifier l'en-tÃªte
          if ! head -1 "$DATASET_PATH" | grep -q "text,label"; then
            echo "âŒ En-tÃªte CSV incorrect"
            exit 1
          fi
          
          echo "âœ… Validation basique OK"
        fi

    - name: ğŸ“Š Dataset Statistics
      if: steps.collect.outputs.dataset-created == 'true'
      run: |
        DATASET_PATH="${{ steps.collect.outputs.dataset-path }}"
        
        echo "ğŸ“Š Statistiques du dataset:"
        echo "=========================="
        
        # Statistiques CSV basiques
        TOTAL_LINES=$(wc -l < "$DATASET_PATH")
        DATA_LINES=$((TOTAL_LINES - 1))  # Exclure l'en-tÃªte
        
        echo "ğŸ“„ Fichier: $DATASET_PATH"
        echo "ğŸ“Š Ã‰chantillons: $DATA_LINES"
        echo "ğŸ’¾ Taille: $(du -h "$DATASET_PATH" | cut -f1)"
        
        # Distribution des labels
        echo ""
        echo "ğŸ·ï¸ Distribution des labels:"
        tail -n +2 "$DATASET_PATH" | cut -d',' -f2 | sort | uniq -c | while read count label; do
          percentage=$(echo "scale=1; $count * 100 / $DATA_LINES" | bc -l)
          echo "  $label: $count ($percentage%)"
        done
        
        # AperÃ§u du contenu
        echo ""
        echo "ğŸ‘€ AperÃ§u du contenu:"
        head -4 "$DATASET_PATH"

    - name: ğŸ“ Commit and Push Dataset
      if: steps.collect.outputs.dataset-created == 'true'
      run: |
        set -euo pipefail
        
        # Configuration Git
        git config user.name "github-actions[bot]"
        git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
        
        DATASET_PATH="${{ steps.collect.outputs.dataset-path }}"
        SAMPLE_COUNT="${{ steps.collect.outputs.sample-count }}"
        TODAY=$(date -u '+%Y-%m-%d')
        
        # VÃ©rifier s'il y a des changements
        git add datasets/
        
        if git diff --staged --quiet && [ "${{ github.event.inputs.force_commit }}" != "true" ]; then
          echo "â„¹ï¸ Aucun changement dÃ©tectÃ© dans les datasets"
          echo "ğŸ’¡ Le dataset pour aujourd'hui existe dÃ©jÃ  ou est identique"
          exit 0
        fi
        
        # CrÃ©er le message de commit avec dÃ©tails
        COMMIT_MSG="ğŸ“° Add daily financial news dataset ($TODAY)

        ğŸ“Š Dataset details:
        - File: $DATASET_PATH
        - Samples: $SAMPLE_COUNT
        - Source: ${{ github.event.inputs.source || 'placeholder' }}
        - Generated: $(date -u '+%Y-%m-%d %H:%M:%S UTC')
        
        ğŸ¤– Auto-generated by Daily News Collection workflow"
        
        # Commit et push
        git commit -m "$COMMIT_MSG"
        
        echo "ğŸš€ Pushing to repository..."
        git push
        
        echo "âœ… Dataset committed and pushed successfully"
        echo "ğŸ”„ This will trigger validation and fine-tuning workflows"

    - name: ğŸ“ Create Summary Comment
      if: always() && github.event_name == 'workflow_dispatch'
      uses: actions/github-script@v7
      with:
        script: |
          const status = '${{ job.status }}';
          const datasetCreated = '${{ steps.collect.outputs.dataset-created }}' === 'true';
          const datasetPath = '${{ steps.collect.outputs.dataset-path }}';
          const sampleCount = '${{ steps.collect.outputs.sample-count }}';
          const source = '${{ github.event.inputs.source }}';
          const runUrl = `${context.payload.repository.html_url}/actions/runs/${context.runId}`;
          
          let emoji, statusText, message;
          
          if (status === 'success' && datasetCreated) {
            emoji = 'âœ…';
            statusText = 'SUCCESS';
            message = `ğŸ‰ Dataset crÃ©Ã© avec succÃ¨s !
            
            **ğŸ“Š DÃ©tails du dataset:**
            - ğŸ“„ Fichier: \`${datasetPath}\`
            - ğŸ“Š Ã‰chantillons: ${sampleCount}
            - ğŸ”— Source: ${source}
            - ğŸ• Timestamp: ${new Date().toISOString()}
            
            **ğŸš€ Prochaines Ã©tapes:**
            Le dataset a Ã©tÃ© committÃ© et va dÃ©clencher automatiquement :
            1. ğŸ” Validation qualitÃ© (Dataset Quality Gate)
            2. ğŸ¤– Fine-tuning automatique (si validation OK)
            3. ğŸš€ DÃ©ploiement sur HuggingFace (si configurÃ©)`;
          } else {
            emoji = 'âŒ';
            statusText = 'FAILED';
            message = `ğŸš¨ Ã‰chec de la collecte de dataset.
            
            **âš ï¸ ProblÃ¨me dÃ©tectÃ©:**
            - Status: ${status}
            - Dataset crÃ©Ã©: ${datasetCreated}
            
            **ğŸ”§ Actions suggÃ©rÃ©es:**
            1. VÃ©rifier les logs du workflow
            2. Tester la collecte localement
            3. VÃ©rifier les dÃ©pendances (feedparser, requests)`;
          }
          
          const commentBody = `## ${emoji} Daily News Collection - ${statusText}
          
          ${message}
          
          ### ğŸ”— Liens utiles
          - ğŸ“Š [Workflow complet](${runUrl})
          - ğŸ”§ Script: \`scripts/collect_news.py\`
          - ğŸ“– [Guide des datasets](DATASET_WORKFLOW.md)
          
          ---
          *ğŸ¤– Rapport automatique de collecte quotidienne*
          `;
          
          // Pour les dÃ©clenchements manuels, crÃ©er une issue ou commentaire
          console.log('Workflow summary:', commentBody);

  # Job optionnel pour notifier en cas d'Ã©chec
  notify-failure:
    runs-on: ubuntu-latest
    needs: collect-and-commit
    if: failure() && github.event_name == 'schedule'
    
    steps:
    - name: ğŸš¨ Notify Collection Failure
      uses: actions/github-script@v7
      with:
        script: |
          // CrÃ©er une issue pour signaler l'Ã©chec de collecte automatique
          const issueBody = `# ğŸš¨ Ã‰chec de la collecte quotidienne de dataset
          
          La collecte automatique de dataset du ${new Date().toISOString().split('T')[0]} a Ã©chouÃ©.
          
          ## ğŸ“Š DÃ©tails
          - **Workflow:** Daily News Dataset Collection
          - **Trigger:** Scheduled (cron)
          - **Timestamp:** ${new Date().toISOString()}
          - **Run ID:** ${context.runId}
          
          ## ğŸ”— Liens
          - [Workflow failed](${context.payload.repository.html_url}/actions/runs/${context.runId})
          - [Script de collecte](${context.payload.repository.html_url}/blob/main/scripts/collect_news.py)
          
          ## ğŸ”§ Actions suggÃ©rÃ©es
          1. VÃ©rifier les logs du workflow
          2. Tester la collecte manuellement
          3. VÃ©rifier la disponibilitÃ© des sources RSS/API
          4. Lancer une collecte manuelle si nÃ©cessaire
          
          ## ğŸ’¡ Collecte manuelle
          Vous pouvez lancer une collecte manuelle via :
          **Actions â†’ Daily News Dataset Collection â†’ Run workflow**
          
          ---
          *Issue crÃ©Ã©e automatiquement par le systÃ¨me de monitoring*
          `;
          
          await github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `ğŸš¨ Ã‰chec collecte automatique dataset ${new Date().toISOString().split('T')[0]}`,
            body: issueBody,
            labels: ['bug', 'automation', 'dataset-collection']
          });
