name: ğŸ” Dataset Quality Gate

on:
  # Validation lors des Pull Requests touchant des datasets
  pull_request:
    paths:
      - 'datasets/**.csv'
      - 'datasets/**.json'
      - 'scripts/validate_dataset.py'
  
  # Validation manuelle
  workflow_dispatch:
    inputs:
      dataset_path:
        description: 'Dataset to validate (relative path from repo root)'
        required: true
        default: 'datasets/news_20250705.csv'
        type: string

jobs:
  validate-datasets:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4
      with:
        # RÃ©cupÃ©rer l'historique pour les diffs dans les PRs
        fetch-depth: 0

    - name: ğŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'

    - name: ğŸ“¦ Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas>=2.0.0 numpy>=1.24.0
        echo "âœ… Dependencies installed"

    - name: ğŸ” Validate Datasets
      run: |
        echo "ğŸ§ª Starting dataset validation..."
        
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          # Validation manuelle d'un dataset spÃ©cifique
          DATASET="${{ github.event.inputs.dataset_path }}"
          echo "ğŸ¯ Manual validation of: $DATASET"
          
          if [ ! -f "$DATASET" ]; then
            echo "âŒ Dataset file not found: $DATASET"
            exit 1
          fi
          
          echo "ğŸ“Š Validating: $DATASET"
          python scripts/validate_dataset.py "$DATASET"
          
        else
          # Validation automatique des fichiers modifiÃ©s dans la PR
          echo "ğŸ”„ PR validation mode"
          
          # Trouver les fichiers CSV/JSON modifiÃ©s
          CHANGED_FILES=$(git diff --name-only origin/${{ github.base_ref }} HEAD | grep -E '^datasets/.*\.(csv|json)$' || true)
          
          if [ -z "$CHANGED_FILES" ]; then
            echo "â„¹ï¸ No dataset files modified in this PR"
            exit 0
          fi
          
          echo "ğŸ“ Modified dataset files:"
          echo "$CHANGED_FILES"
          echo ""
          
          # Valider chaque fichier modifiÃ©
          VALIDATION_FAILED=false
          
          for dataset in $CHANGED_FILES; do
            echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
            echo "ğŸ” Validating: $dataset"
            echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
            
            if [ ! -f "$dataset" ]; then
              echo "âŒ File was deleted or moved: $dataset"
              continue
            fi
            
            if python scripts/validate_dataset.py "$dataset"; then
              echo "âœ… $dataset passed validation"
            else
              echo "âŒ $dataset failed validation"
              VALIDATION_FAILED=true
            fi
            echo ""
          done
          
          if [ "$VALIDATION_FAILED" = "true" ]; then
            echo "âŒ One or more datasets failed validation"
            echo "ğŸ’¡ Please fix the issues above before merging"
            exit 1
          fi
          
          echo "âœ… All modified datasets passed validation!"
        fi

    - name: ğŸ“Š Generate Validation Report
      if: always()
      run: |
        echo "ğŸ“‹ Dataset Validation Summary"
        echo "============================="
        echo "ğŸ• Timestamp: $(date -u +"%Y-%m-%d %H:%M:%S UTC")"
        echo "ğŸŒ¿ Branch: ${{ github.head_ref || github.ref_name }}"
        echo "ğŸ‘¤ Author: ${{ github.actor }}"
        
        if [ "${{ github.event_name }}" = "pull_request" ]; then
          echo "ğŸ”— PR: #${{ github.event.number }}"
          echo "ğŸ“ Title: ${{ github.event.pull_request.title }}"
        fi
        
        echo ""
        echo "ğŸ“ Repository datasets:"
        find datasets/ -name "*.csv" -o -name "*.json" | head -10 | while read file; do
          size=$(du -h "$file" 2>/dev/null | cut -f1 || echo "?")
          echo "  ğŸ“„ $file ($size)"
        done
        
        total_datasets=$(find datasets/ -name "*.csv" -o -name "*.json" | wc -l)
        echo "ğŸ“Š Total datasets: $total_datasets"

  # Job de commentaire automatique sur la PR (optionnel)
  comment-pr:
    runs-on: ubuntu-latest
    needs: validate-datasets
    if: github.event_name == 'pull_request' && always()
    
    steps:
    - name: ğŸ“ Comment PR Results
      uses: actions/github-script@v7
      with:
        script: |
          const jobStatus = '${{ needs.validate-datasets.result }}';
          const runUrl = `${context.payload.repository.html_url}/actions/runs/${context.runId}`;
          
          let emoji, status, message;
          
          if (jobStatus === 'success') {
            emoji = 'âœ…';
            status = 'PASSED';
            message = 'All dataset validations passed! Your datasets are ready for training.';
          } else if (jobStatus === 'failure') {
            emoji = 'âŒ';
            status = 'FAILED';
            message = 'Dataset validation failed. Please check the validation report and fix the issues.';
          } else {
            emoji = 'âš ï¸';
            status = 'CANCELLED/SKIPPED';
            message = 'Dataset validation was cancelled or skipped.';
          }
          
          const comment = `
          ## ${emoji} Dataset Quality Gate - ${status}
          
          ${message}
          
          **Details:**
          - ğŸ”— [View full validation report](${runUrl})
          - ğŸ“Š Validation script: \`scripts/validate_dataset.py\`
          - ğŸ¯ Trigger: Dataset files modified in PR
          
          ---
          
          ### Next steps:
          ${jobStatus === 'success' 
            ? 'ğŸš€ Ready to merge! The fine-tuning job will start automatically after merge.'
            : 'ğŸ”§ Fix validation issues and push new changes to re-trigger validation.'
          }
          `;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });

  # PrÃ©parer les artifacts pour debug si nÃ©cessaire
  upload-artifacts:
    runs-on: ubuntu-latest
    needs: validate-datasets
    if: always() && github.event_name == 'pull_request'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: ğŸ“¤ Upload Validation Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: dataset-validation-${{ github.event.number }}
        path: |
          datasets/
          scripts/validate_dataset.py
        retention-days: 7
