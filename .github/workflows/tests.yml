name: ðŸ§ª Tests & Code Quality

on:
  # Tests sur toutes les PRs et pushs vers main
  push:
    branches: [main]
  pull_request:
    branches: [main]
  
  # Tests manuels
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type de tests Ã  exÃ©cuter'
        required: true
        default: 'all'
        type: choice
        options:
          - 'all'
          - 'validation-only'
          - 'linting-only'
          - 'security-only'

  # Tests programmÃ©s (daily)
  schedule:
    - cron: '0 6 * * *'  # 6h UTC tous les jours

jobs:
  # Job de tests unitaires
  unit-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
      fail-fast: false
    
    steps:
    - name: ðŸ“¥ Checkout Repository
      uses: actions/checkout@v4

    - name: ðŸ Setup Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: ðŸ“¦ Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas>=2.0.0 numpy>=1.24.0
        
        # Installer pytest si disponible pour tests plus avancÃ©s
        pip install pytest pytest-cov pytest-xdist || echo "pytest optional"
        
        # Installer les dÃ©pendances du projet
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        fi

    - name: ðŸ§ª Run Dataset Validation Tests
      if: github.event.inputs.test_type != 'linting-only' && github.event.inputs.test_type != 'security-only'
      run: |
        echo "ðŸ§ª Testing dataset validation script..."
        cd scripts
        
        # Tester avec ou sans pytest
        if command -v pytest &> /dev/null; then
          echo "ðŸš€ Using pytest for comprehensive testing"
          pytest test_validation.py -v --tb=short --cov=validate_dataset
        else
          echo "ðŸ”§ Using manual test runner"
          python test_validation.py
        fi

    - name: ðŸ” Test Validation on Sample Datasets
      if: github.event.inputs.test_type != 'linting-only' && github.event.inputs.test_type != 'security-only'
      run: |
        echo "ðŸ” Testing validation on actual datasets..."
        
        # Tester sur les datasets existants
        for dataset in datasets/*.csv; do
          if [ -f "$dataset" ]; then
            echo "Testing $dataset..."
            python scripts/validate_dataset.py "$dataset" --quiet || {
              echo "âš ï¸ Validation failed for $dataset (might be expected for test datasets)"
            }
          fi
        done
        
        # Test avec dataset invalide volontaire
        echo "text,label" > test_invalid.csv
        echo '"Test text",invalid_label' >> test_invalid.csv
        
        if python scripts/validate_dataset.py test_invalid.csv --quiet; then
          echo "âŒ Validation should have failed for invalid dataset"
          exit 1
        else
          echo "âœ… Validation correctly failed for invalid dataset"
        fi
        
        rm -f test_invalid.csv

    - name: ðŸ§ª Test Fine-tuning Script Imports
      if: github.event.inputs.test_type != 'linting-only' && github.event.inputs.test_type != 'security-only'
      run: |
        echo "ðŸ§ª Testing fine-tuning script imports..."
        python -c "
        import sys
        sys.path.append('scripts')
        try:
            import finetune
            print('âœ… Fine-tuning script imports OK')
        except ImportError as e:
            print(f'âš ï¸ Fine-tuning import issue (expected in CI): {e}')
        except Exception as e:
            print(f'âŒ Unexpected error: {e}')
            sys.exit(1)
        "

  # Job de qualitÃ© du code (linting)
  code-quality:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: ðŸ“¥ Checkout Repository
      uses: actions/checkout@v4

    - name: ðŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'

    - name: ðŸ“¦ Install Linting Tools
      if: github.event.inputs.test_type != 'validation-only' && github.event.inputs.test_type != 'security-only'
      run: |
        pip install --upgrade pip
        # isort retirÃ© ; on garde seulement Ruff
        pip install "ruff==0.3.4" pre-commit

    - name: ðŸ” Show Tool Versions
      if: github.event.inputs.test_type != 'validation-only' && github.event.inputs.test_type != 'security-only'
      run: |
        echo "ðŸ” Tool versions for debugging:"
        python -m ruff --version

    - name: âš¡ Run Ruff Linting
      if: github.event.inputs.test_type != 'validation-only' && github.event.inputs.test_type != 'security-only'
      run: |
        echo "âš¡ Running Ruff linting..."
        ruff check scripts/ --show-source || {
          echo "âŒ Linting issues found"
          echo "ðŸ’¡ Run: ruff check scripts/ --fix"
          exit 1
        }

    - name: ðŸŽ£ Test Pre-commit Hooks
      if: github.event.inputs.test_type != 'validation-only' && github.event.inputs.test_type != 'security-only'
      run: |
        echo "ðŸŽ£ Testing pre-commit configuration..."
        
        # Installer et tester pre-commit
        pre-commit install
        
        # Tester les hooks sur quelques fichiers
        pre-commit run --files scripts/validate_dataset.py || {
          echo "âš ï¸ Pre-commit hooks found issues (might be fixable)"
        }
        
        echo "âœ… Pre-commit configuration tested"

  # Job de sÃ©curitÃ©
  security-checks:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: ðŸ“¥ Checkout Repository
      uses: actions/checkout@v4

    - name: ðŸ” Check for Exposed Secrets
      if: github.event.inputs.test_type != 'validation-only' && github.event.inputs.test_type != 'linting-only'
      run: |
        echo "ðŸ” Checking for exposed secrets..."
        
        # Patterns de secrets courants
        SECRET_PATTERNS=(
          "api_key\s*=\s*[\"'][^\"']+[\"']"
          "secret\s*=\s*[\"'][^\"']+[\"']"
          "token\s*=\s*[\"'][^\"']+[\"']"
          "password\s*=\s*[\"'][^\"']+[\"']"
          "sk-[a-zA-Z0-9]{48}"  # OpenAI API keys
          "hf_[a-zA-Z0-9]{37}"  # HuggingFace tokens
        )
        
        SECRETS_FOUND=false
        
        for pattern in "${SECRET_PATTERNS[@]}"; do
          if grep -r -E "$pattern" --include="*.py" --include="*.yml" --include="*.yaml" --include="*.json" . | grep -v ".git"; then
            echo "âŒ Potential secret found matching pattern: $pattern"
            SECRETS_FOUND=true
          fi
        done
        
        if [ "$SECRETS_FOUND" = true ]; then
          echo "ðŸš¨ Secrets or tokens detected in code!"
          echo "ðŸ’¡ Use environment variables or GitHub Secrets instead"
          exit 1
        else
          echo "âœ… No exposed secrets found"
        fi

    - name: ðŸ” Check File Permissions
      if: github.event.inputs.test_type != 'validation-only' && github.event.inputs.test_type != 'linting-only'
      run: |
        echo "ðŸ” Checking file permissions..."
        
        # VÃ©rifier les permissions des scripts
        if [ -f "scripts/validate_dataset.py" ] && [ ! -x "scripts/validate_dataset.py" ]; then
          echo "âš ï¸ validate_dataset.py should be executable"
        fi
        
        if [ -f "scripts/finetune.py" ] && [ ! -x "scripts/finetune.py" ]; then
          echo "âš ï¸ finetune.py should be executable"
        fi
        
        echo "âœ… File permissions checked"

    - name: ðŸ“ Check File Sizes
      if: github.event.inputs.test_type != 'validation-only' && github.event.inputs.test_type != 'linting-only'
      run: |
        echo "ðŸ“ Checking for large files..."
        
        # Chercher les gros fichiers (>10MB)
        find . -type f -size +10M | grep -v .git | while read file; do
          size=$(du -h "$file" | cut -f1)
          echo "âš ï¸ Large file detected: $file ($size)"
          
          # Bloquer si c'est un modÃ¨le sans LFS
          if [[ "$file" =~ \.(bin|pt|pth|safetensors)$ ]]; then
            echo "âŒ Model file should use Git LFS: $file"
            exit 1
          fi
        done || exit 1
        
        echo "âœ… File sizes OK"

  # Job de validation des workflows
  workflow-validation:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    
    steps:
    - name: ðŸ“¥ Checkout Repository
      uses: actions/checkout@v4

    - name: ðŸ” Validate GitHub Actions Workflows
      run: |
        echo "ðŸ” Validating GitHub Actions workflows..."
        
        # VÃ©rifier la syntaxe YAML
        for workflow in .github/workflows/*.yml .github/workflows/*.yaml; do
          if [ -f "$workflow" ]; then
            echo "Validating $workflow..."
            python -c "
        import yaml
        import sys
        try:
            with open('$workflow', 'r') as f:
                yaml.safe_load(f)
            print('âœ… $workflow syntax OK')
        except Exception as e:
            print(f'âŒ $workflow syntax error: {e}')
            sys.exit(1)
            " || exit 1
          fi
        done

    - name: ðŸ“‹ Check Workflow Dependencies
      run: |
        echo "ðŸ“‹ Checking workflow dependencies..."
        
        # VÃ©rifier que les workflows rÃ©fÃ©rencent des actions existantes
        for workflow in .github/workflows/*.yml; do
          if [ -f "$workflow" ]; then
            echo "Checking dependencies in $workflow..."
            
            # VÃ©rifier les versions d'actions couramment utilisÃ©es
            if grep -q "actions/checkout@v3" "$workflow"; then
              echo "âš ï¸ $workflow uses old checkout@v3, consider updating to v4"
            fi
            
            if grep -q "actions/setup-python@v3" "$workflow"; then
              echo "âš ï¸ $workflow uses old setup-python@v3, consider updating to v4"
            fi
          fi
        done
        
        echo "âœ… Workflow dependencies checked"

  # Job de synthÃ¨se
  test-summary:
    runs-on: ubuntu-latest
    needs: [unit-tests, code-quality, security-checks, workflow-validation]
    if: always()
    
    steps:
    - name: ðŸ“Š Test Summary
      run: |
        echo "ðŸ“Š Test Summary Report"
        echo "====================="
        echo ""
        
        # Statuts des jobs
        echo "ðŸ§ª Unit Tests: ${{ needs.unit-tests.result }}"
        echo "ðŸ” Code Quality: ${{ needs.code-quality.result }}"
        echo "ðŸ” Security Checks: ${{ needs.security-checks.result }}"
        echo "âš™ï¸ Workflow Validation: ${{ needs.workflow-validation.result }}"
        echo ""
        
        # DÃ©terminer le statut global
        if [ "${{ needs.unit-tests.result }}" = "success" ] && \
           [ "${{ needs.code-quality.result }}" = "success" ] && \
           [ "${{ needs.security-checks.result }}" = "success" ] && \
           [ "${{ needs.workflow-validation.result }}" = "success" ]; then
          echo "âœ… All tests passed! ðŸŽ‰"
          echo "status=success" >> $GITHUB_OUTPUT
        else
          echo "âŒ Some tests failed"
          echo "status=failure" >> $GITHUB_OUTPUT
        fi
        
        echo ""
        echo "ðŸ”— View detailed results in the Actions tab"

    - name: ðŸŽ‰ Success Notification
      if: needs.unit-tests.result == 'success' && needs.code-quality.result == 'success' && needs.security-checks.result == 'success'
      run: |
        echo "ðŸŽ‰ All quality checks passed!"
        echo "âœ… Code ready for production"
        echo "ðŸš€ Ready to merge or deploy"
