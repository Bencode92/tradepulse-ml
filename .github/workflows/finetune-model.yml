name: 🤖 TradePulse FinBERT Fine-tuning

on:
  # Déclenchement manuel avec paramètres
  workflow_dispatch:
    inputs:
      dataset:
        description: 'Dataset filename (in datasets/ folder)'
        required: true
        default: 'auto-latest'
        type: string
      
      model_name:
        description: 'Base model to fine-tune'
        required: true
        default: 'yiyanghkust/finbert-tone'
        type: choice
        options:
          - 'yiyanghkust/finbert-tone'
          - 'ProsusAI/finbert'
          - 'nlptown/bert-base-multilingual-uncased-sentiment'
      
      epochs:
        description: 'Number of training epochs'
        required: true
        default: '3'
        type: string
      
      learning_rate:
        description: 'Learning rate'
        required: true
        default: '2e-5'
        type: string
      
      push_to_hub:
        description: 'Push model to HuggingFace Hub'
        required: true
        default: false
        type: boolean

  # Déclenchement sur push dans datasets/ (après validation quality gate)
  push:
    paths:
      - 'datasets/**.csv'
      - 'datasets/**.json'
      - 'scripts/finetune.py'

jobs:
  finetune:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # 2 heures max

    steps:
    - name: 📥 Checkout Repository
      uses: actions/checkout@v4
      with:
        lfs: true

    - name: 🐍 Setup Python 3.9
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'

    - name: 🔧 Smart Dataset Selection
      run: |
        echo "🎯 Selecting dataset for training..."
        
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          MANUAL_DATASET="${{ github.event.inputs.dataset }}"
          
          if [ "$MANUAL_DATASET" = "auto-latest" ]; then
            echo "🔍 Auto-selecting latest dataset..."
            # Sélectionner le dernier CSV ajouté (par date de modification)
            LATEST_CSV=$(find datasets/ -name "*.csv" -type f -exec ls -t {} + | head -1 | xargs basename)
            if [ -z "$LATEST_CSV" ]; then
              echo "❌ No CSV files found in datasets/"
              exit 1
            fi
            echo "DATASET=$LATEST_CSV" >> $GITHUB_ENV
            echo "📊 Auto-selected dataset: $LATEST_CSV"
          else
            echo "DATASET=$MANUAL_DATASET" >> $GITHUB_ENV
            echo "📊 Manual dataset: $MANUAL_DATASET"
          fi
          
          echo "MODEL_NAME=${{ github.event.inputs.model_name }}" >> $GITHUB_ENV
          echo "EPOCHS=${{ github.event.inputs.epochs }}" >> $GITHUB_ENV
          echo "LEARNING_RATE=${{ github.event.inputs.learning_rate }}" >> $GITHUB_ENV
          echo "PUSH_TO_HUB=${{ github.event.inputs.push_to_hub }}" >> $GITHUB_ENV
        else
          # Déclenchement automatique après push
          echo "🔄 Auto-trigger mode: selecting latest dataset..."
          
          # Trouver le dernier dataset modifié/ajouté
          CHANGED_DATASETS=$(git diff --name-only HEAD~1 HEAD | grep -E '^datasets/.*\.(csv|json)$' || true)
          
          if [ -n "$CHANGED_DATASETS" ]; then
            # Prendre le premier dataset modifié
            DATASET_FILE=$(echo "$CHANGED_DATASETS" | head -1 | xargs basename)
            echo "📝 Using modified dataset: $DATASET_FILE"
          else
            # Fallback: prendre le plus récent CSV
            DATASET_FILE=$(find datasets/ -name "*.csv" -type f -exec ls -t {} + | head -1 | xargs basename)
            echo "📊 Using latest available dataset: $DATASET_FILE"
          fi
          
          if [ -z "$DATASET_FILE" ]; then
            echo "❌ No suitable dataset found"
            exit 1
          fi
          
          echo "DATASET=$DATASET_FILE" >> $GITHUB_ENV
          echo "MODEL_NAME=yiyanghkust/finbert-tone" >> $GITHUB_ENV
          echo "EPOCHS=3" >> $GITHUB_ENV
          echo "LEARNING_RATE=2e-5" >> $GITHUB_ENV
          echo "PUSH_TO_HUB=false" >> $GITHUB_ENV
        fi
        
        echo ""
        echo "🔧 Final configuration:"
        echo "  Trigger: ${{ github.event_name }}"
        echo "  Dataset: $DATASET"
        echo "  Model: $MODEL_NAME"
        echo "  Epochs: $EPOCHS"
        echo "  Learning Rate: $LEARNING_RATE"
        echo "  Push to Hub: $PUSH_TO_HUB"

    - name: 📦 Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip cache purge
        pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
        pip install "transformers[torch]==4.41.0" datasets==2.19.1 accelerate==0.30.1 evaluate==0.4.2
        pip install scikit-learn==1.4.2 pandas==2.2.2 numpy==1.26.4
        pip install huggingface_hub==0.23.0 tensorboard==2.16.2
        
        if [ -f requirements.txt ]; then
          echo "📋 Installing additional requirements..."
          pip install -r requirements.txt
        fi
        
        # ── Vérifications de version ──
        python - <<'PY'
        import transformers, torch, datasets, sys
        print(f"✅ Transformers: {transformers.__version__}")
        print(f"✅ PyTorch: {torch.__version__}")
        print(f"✅ Datasets: {datasets.__version__}")
        
        from transformers import TrainingArguments
        try:
            TrainingArguments(output_dir="/tmp", evaluation_strategy="epoch")
            print("✅ evaluation_strategy parameter supported")
        except Exception as e:
            print(f"❌ evaluation_strategy error: {e}")
            sys.exit(1)
        PY

    - name: 🔐 Setup HuggingFace Token
      if: env.PUSH_TO_HUB == 'true'
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
      run: |
        if [ -z "$HF_TOKEN" ]; then
          echo "❌ HF_TOKEN required for push_to_hub=true"
          echo "💡 Add HF_TOKEN to repository secrets in Settings > Secrets"
          exit 1
        fi
        
        huggingface-cli login --token "$HF_TOKEN"
        echo "✅ HuggingFace authentication successful"
        
        # Vérification de l'authentification
        huggingface-cli whoami || {
          echo "❌ HuggingFace authentication failed"
          exit 1
        }

    - name: 🔍 Validate Dataset Quality
      run: |
        DATASET_FILE="datasets/$DATASET"
        echo "🧪 Validating dataset quality: $DATASET_FILE"
        
        if [ ! -f "$DATASET_FILE" ]; then
          echo "❌ Dataset file not found: $DATASET_FILE"
          echo "📁 Available files in datasets/:"
          find datasets/ -name "*.csv" -o -name "*.json" | head -10
          exit 1
        fi
        
        echo "✅ Dataset file found: $DATASET_FILE"
        echo "📊 File size: $(du -h "$DATASET_FILE" | cut -f1)"
        
        # Utiliser notre script de validation
        if [ -f "scripts/validate_dataset.py" ]; then
          echo "🔍 Running comprehensive validation..."
          python scripts/validate_dataset.py "$DATASET_FILE" || {
            echo "❌ Dataset validation failed!"
            echo "💡 Fix the issues above before proceeding with training"
            exit 1
          }
          echo "✅ Dataset validation passed!"
        else
          echo "⚠️ Validation script not found, using basic checks..."
          # Validation basique pour compatibilité
          echo "👀 Dataset preview:"
          head -3 "$DATASET_FILE"
          
          if [[ "$DATASET_FILE" == *.csv ]]; then
            if ! head -1 "$DATASET_FILE" | grep -q "text.*label"; then
              echo "⚠️ CSV header should contain 'text' and 'label' columns"
              echo "📋 Current header: $(head -1 "$DATASET_FILE")"
            fi
          fi
        fi

    - name: 🤖 Run Fine-tuning
      run: |
        echo "🚀 Starting FinBERT fine-tuning..."
        echo "📋 Configuration:"
        echo "  Dataset: $DATASET"
        echo "  Model: $MODEL_NAME"
        echo "  Epochs: $EPOCHS"
        echo "  Learning Rate: $LEARNING_RATE"
        echo "  Push to Hub: $PUSH_TO_HUB"
        
        OUTPUT_DIR="models/finbert-$(date +%Y%m%d_%H%M%S)"
        mkdir -p "$OUTPUT_DIR"
        echo "📁 Output directory: $OUTPUT_DIR"
        
        ARGS="--dataset datasets/$DATASET --output_dir $OUTPUT_DIR --model_name $MODEL_NAME --epochs $EPOCHS --lr $LEARNING_RATE"
        
        if [ "$PUSH_TO_HUB" = "true" ]; then
          HUB_ID="Bencode92/tradepulse-finbert-$(date +%Y%m%d-%H%M)"
          ARGS="$ARGS --push --hub_id $HUB_ID"
          echo "🚀 Will push to HuggingFace Hub as: $HUB_ID"
        fi
        
        echo "🔥 Launching training with args: $ARGS"
        
        python scripts/finetune.py $ARGS || {
          echo "❌ Training failed, showing logs..."
          [ -f finetune.log ] && tail -20 finetune.log
          exit 1
        }
        
        echo "✅ Training completed successfully!"

    - name: 📈 Training Summary
      if: always()
      run: |
        echo "📊 Training Summary:"
        echo "===================="
        
        if find models/ -name "training_report.json" -type f | head -1 | grep -q .; then
          echo "📄 Training reports found:"
          find models/ -name "training_report.json" -exec echo "  📋 {}" \;
          echo ""
          echo "📈 Latest training metrics:"
          find models/ -name "training_report.json" -exec cat {} \; | head -50
        else
          echo "⚠️ No training report found"
        fi
        
        echo ""
        echo "📁 Generated model directories:"
        find models/ -type d -name "finbert-*" | head -5 || echo "No model directories found"
        
        echo ""
        echo "📝 Log files:"
        ls -la *.log 2>/dev/null || echo "No log files found"

    - name: 📤 Upload Model Artifacts
      if: success()
      uses: actions/upload-artifact@v4
      with:
        name: tradepulse-finbert-${{ github.run_id }}
        path: |
          models/**
          finetune.log
        retention-days: 30

    - name: 📤 Upload Logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: training-logs-${{ github.run_id }}
        path: |
          finetune.log
          models/**/logs/**
        retention-days: 7

    - name: 🎉 Success Notification
      if: success()
      run: |
        echo "✅ Fine-tuning completed successfully!"
        echo "🔍 Check the 'Actions' tab for downloadable artifacts"
        echo "📊 Model saved in: $(find models/ -type d -name "finbert-*" | head -1)"
        if [ "$PUSH_TO_HUB" = "true" ]; then
          echo "🚀 Model pushed to HuggingFace Hub"
        fi
        
        echo ""
        echo "📋 Final Summary:"
        echo "  Dataset: $DATASET"
        echo "  Model: $MODEL_NAME"
        echo "  Epochs: $EPOCHS"
        echo "  Status: SUCCESS ✅"
