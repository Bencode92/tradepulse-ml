name: 🤖 TradePulse FinBERT - Auto-Detection Multi-Modèles

# 🔐 PERMISSIONS REQUISES POUR RELEASES
permissions:
  contents: write      # Pour créer des releases et tags
  actions: read        # Pour lire les workflows
  issues: write        # Pour commenter sur les issues/PRs
  pull-requests: write # Pour commenter sur les PRs

on:
  # Déclenchement manuel avec paramètres
  workflow_dispatch:
    inputs:
      dataset:
        description: 'Dataset filename (in datasets/ folder)'
        required: true
        default: 'auto-latest'
        type: string
      
      mode:
        description: 'Training mode'
        required: true
        default: 'incremental'
        type: choice
        options:
          - 'incremental'      # Améliore le modèle existant (RECOMMANDÉ)
          - 'fresh'            # Repart du modèle de base
          - 'test'             # Test local seulement
      
      epochs:
        description: 'Number of training epochs'
        required: true
        default: '3'
        type: string
      
      learning_rate:
        description: 'Learning rate'
        required: true
        default: '2e-5'
        type: string
      
      force_update:
        description: 'Force update even without improvement'
        required: false
        default: false
        type: boolean

  # Déclenchement sur push dans datasets/ (après validation quality gate)
  push:
    paths:
      - 'datasets/**.csv'
      - 'datasets/**.json'
      - 'scripts/finetune.py'
      
  # Déclenchement après succès du Quality Gate (pour PRs)
  workflow_run:
    workflows: ["🔍 Dataset Quality Gate"]
    types:
      - completed
    branches: [main]

env:
  # 🎯 MODÈLES SPÉCIALISÉS - Auto-détection
  SENTIMENT_MODEL: "Bencode92/tradepulse-finbert-sentiment"
  IMPORTANCE_MODEL: "Bencode92/tradepulse-finbert-importance" 
  FALLBACK_MODEL: "yiyanghkust/finbert-tone"

jobs:
  # Job de vérification des prérequis
  check-prerequisites:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    
    outputs:
      should-run: ${{ steps.check.outputs.should-run }}
      trigger-reason: ${{ steps.check.outputs.trigger-reason }}
      dataset-changed: ${{ steps.check.outputs.dataset-changed }}
      training-mode: ${{ steps.check.outputs.training-mode }}
      
    steps:
    - name: 📥 Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 2  # Pour comparer avec le commit précédent
    
    - name: 🔍 Check Prerequisites & Determine Mode
      id: check
      run: |
        set -euo pipefail
        
        SHOULD_RUN=false
        TRIGGER_REASON=""
        DATASET_CHANGED=false
        TRAINING_MODE="incremental"  # Mode par défaut
        
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          SHOULD_RUN=true
          TRIGGER_REASON="Manual trigger"
          TRAINING_MODE="${{ github.event.inputs.mode }}"
          
          echo "🎯 Manual mode selected: $TRAINING_MODE"
          
        elif [ "${{ github.event_name }}" = "push" ]; then
          # Vérifier si des datasets ont changé
          if git diff --name-only HEAD~1 HEAD | grep -E '^datasets/.*\.(csv|json)$'; then
            SHOULD_RUN=true
            TRIGGER_REASON="Dataset files modified"
            DATASET_CHANGED=true
            TRAINING_MODE="incremental"  # Auto = toujours incrémental
          elif git diff --name-only HEAD~1 HEAD | grep '^scripts/finetune.py$'; then
            SHOULD_RUN=true
            TRIGGER_REASON="Fine-tuning script modified"
            TRAINING_MODE="incremental"
          fi
          
        elif [ "${{ github.event_name }}" = "workflow_run" ]; then
          # Vérifier si le Quality Gate a réussi
          if [ "${{ github.event.workflow_run.conclusion }}" = "success" ]; then
            SHOULD_RUN=true
            TRIGGER_REASON="Quality Gate passed"
            DATASET_CHANGED=true
            TRAINING_MODE="incremental"
          else
            echo "⚠️ Quality Gate failed, skipping fine-tuning"
          fi
        fi
        
        echo "should-run=$SHOULD_RUN" >> $GITHUB_OUTPUT
        echo "trigger-reason=$TRIGGER_REASON" >> $GITHUB_OUTPUT  
        echo "dataset-changed=$DATASET_CHANGED" >> $GITHUB_OUTPUT
        echo "training-mode=$TRAINING_MODE" >> $GITHUB_OUTPUT
        
        echo "🔍 Prerequisites check:"
        echo "  Should run: $SHOULD_RUN"
        echo "  Reason: $TRIGGER_REASON"
        echo "  Dataset changed: $DATASET_CHANGED"
        echo "  Training mode: $TRAINING_MODE"

  finetune:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # 2 heures max
    needs: check-prerequisites
    if: needs.check-prerequisites.outputs.should-run == 'true'
    
    outputs:
      models-trained: ${{ steps.training.outputs.models-trained }}
      sentiment-updated: ${{ steps.training.outputs.sentiment-updated }}
      importance-updated: ${{ steps.training.outputs.importance-updated }}
      training-strategy: ${{ steps.detect.outputs.training-strategy }}

    steps:
    - name: 📥 Checkout Repository
      uses: actions/checkout@v4
      with:
        lfs: true
        fetch-depth: 2
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: 🐍 Setup Python 3.9
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'

    - name: 🔧 Smart Configuration
      id: config
      run: |
        set -euo pipefail
        
        # Déterminer le dataset
        TRAINING_MODE="${{ needs.check-prerequisites.outputs.training-mode }}"
        
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          MANUAL_DATASET="${{ github.event.inputs.dataset }}"
          
          if [ "$MANUAL_DATASET" = "auto-latest" ]; then
            LATEST_CSV=$(find datasets/ -name "*.csv" -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f2- | xargs basename)
            if [ -z "$LATEST_CSV" ]; then
              echo "❌ No CSV files found in datasets/"
              exit 1
            fi
            DATASET="$LATEST_CSV"
          else
            DATASET="$MANUAL_DATASET"
          fi
          
          EPOCHS="${{ github.event.inputs.epochs }}"
          LEARNING_RATE="${{ github.event.inputs.learning_rate }}"
          FORCE_UPDATE="${{ github.event.inputs.force_update }}"
        else
          # Auto-trigger: sélectionner le dernier dataset modifié
          DATASET_FILE=$(find datasets/ -name "*.csv" -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f2- | xargs basename)
          if [ -z "$DATASET_FILE" ]; then
            echo "❌ No suitable dataset found"
            exit 1
          fi
          
          DATASET="$DATASET_FILE"
          EPOCHS="3"
          LEARNING_RATE="2e-5"
          FORCE_UPDATE="false"
        fi
        
        # Export des variables
        {
          echo "DATASET=$DATASET"
          echo "EPOCHS=$EPOCHS"
          echo "LEARNING_RATE=$LEARNING_RATE"
          echo "FORCE_UPDATE=$FORCE_UPDATE"
          echo "TRAINING_MODE=$TRAINING_MODE"
        } >> "$GITHUB_ENV"
        
        echo "🔧 Configuration:"
        echo "  Dataset: $DATASET"
        echo "  Training Mode: $TRAINING_MODE"
        echo "  Epochs: $EPOCHS"
        echo "  Learning Rate: $LEARNING_RATE"

    - name: 📦 Install Dependencies
      run: |
        set -euo pipefail
        
        python -m pip install --upgrade pip
        pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
        pip install "transformers[torch]==4.41.0" datasets==2.19.1 accelerate==0.30.1 evaluate==0.4.2
        pip install scikit-learn==1.4.2 pandas==2.2.2 numpy==1.26.4
        pip install huggingface_hub==0.23.0 tensorboard==2.16.2
        
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        fi

    - name: 🔐 Setup HuggingFace Token
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
      run: |
        set -euo pipefail
        
        if [ -z "$HF_TOKEN" ]; then
          echo "❌ HF_TOKEN required for model updates"
          exit 1
        fi
        
        huggingface-cli login --token "$HF_TOKEN"
        echo "✅ HuggingFace authentication successful"

    - name: 🔍 Validate Dataset Quality
      run: |
        set -euo pipefail
        
        DATASET_FILE="datasets/$DATASET"
        echo "🧪 Validating dataset quality: $DATASET_FILE"
        
        if [ ! -f "$DATASET_FILE" ]; then
          echo "❌ Dataset file not found: $DATASET_FILE"
          exit 1
        fi
        
        if [ -f "scripts/validate_dataset.py" ]; then
          if python scripts/validate_dataset.py "$DATASET_FILE" --output-json "pre_training_validation.json"; then
            echo "✅ Dataset validation passed!"
          else
            echo "❌ Dataset validation failed!"
            exit 1
          fi
        fi

    - name: 🧠 Smart Column Detection & Training Strategy
      id: detect
      run: |
        set -euo pipefail
        
        # Créer le script d'auto-détection
        cat > scripts/auto_detect_columns.py << 'EOF'
        #!/usr/bin/env python3
        import pandas as pd
        import json
        import sys
        from pathlib import Path
        
        def detect_training_columns(dataset_path):
            if dataset_path.suffix.lower() == '.csv':
                df = pd.read_csv(dataset_path)
            else:
                df = pd.read_json(dataset_path)
            
            columns = set(df.columns.str.lower())
            has_label = 'label' in columns
            has_importance = 'importance' in columns
            sample_size = len(df)
            
            if has_label and has_importance and sample_size >= 30:
                strategy = 'dual_model'
                models = [
                    {'target': 'sentiment', 'column': 'label'},
                    {'target': 'importance', 'column': 'importance'}
                ]
            elif has_label:
                strategy = 'sentiment_only'
                models = [{'target': 'sentiment', 'column': 'label'}]
            elif has_importance:
                strategy = 'importance_only'
                models = [{'target': 'importance', 'column': 'importance'}]
            else:
                strategy = 'error'
                models = []
            
            return {
                'strategy': strategy,
                'models': models,
                'sample_size': sample_size,
                'has_label': has_label,
                'has_importance': has_importance
            }
        
        if __name__ == "__main__":
            result = detect_training_columns(Path(sys.argv[1]))
            print(json.dumps(result))
        EOF
        
        DATASET_FILE="datasets/$DATASET"
        echo "🧠 Analyzing dataset structure: $DATASET_FILE"
        
        # Analyser le dataset
        DETECTION_RESULT=$(python scripts/auto_detect_columns.py "$DATASET_FILE")
        echo "$DETECTION_RESULT" > training_strategy.json
        
        STRATEGY=$(echo "$DETECTION_RESULT" | jq -r '.strategy')
        MODELS_COUNT=$(echo "$DETECTION_RESULT" | jq -r '.models | length')
        HAS_LABEL=$(echo "$DETECTION_RESULT" | jq -r '.has_label')
        HAS_IMPORTANCE=$(echo "$DETECTION_RESULT" | jq -r '.has_importance')
        
        echo "🎯 Detected strategy: $STRATEGY"
        echo "🤖 Models to train: $MODELS_COUNT"
        echo "😊 Has sentiment: $HAS_LABEL"
        echo "🎯 Has importance: $HAS_IMPORTANCE"
        
        # Exporter les variables
        echo "TRAINING_STRATEGY=$STRATEGY" >> $GITHUB_ENV
        echo "HAS_LABEL=$HAS_LABEL" >> $GITHUB_ENV
        echo "HAS_IMPORTANCE=$HAS_IMPORTANCE" >> $GITHUB_ENV
        echo "training-strategy=$STRATEGY" >> $GITHUB_OUTPUT
        
        # Créer les répertoires de sortie
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        echo "TIMESTAMP=$TIMESTAMP" >> $GITHUB_ENV

    - name: 🤖 Train Multi-Model Strategy
      id: training
      run: |
        set -euo pipefail
        
        echo "🚀 Starting Smart Multi-Model Training..."
        echo "📋 Strategy: $TRAINING_STRATEGY"
        
        DATASET_FILE="datasets/$DATASET"
        MODELS_TRAINED=0
        SENTIMENT_UPDATED=false
        IMPORTANCE_UPDATED=false
        
        # Arguments communs
        COMMON_ARGS="--epochs $EPOCHS --lr $LEARNING_RATE"
        if [ "$FORCE_UPDATE" = "true" ]; then
          COMMON_ARGS="$COMMON_ARGS --force-update"
        fi
        
        # Entraîner le modèle de sentiment si disponible
        if [ "$HAS_LABEL" = "true" ]; then
          echo "😊 Training sentiment model..."
          SENTIMENT_OUTPUT="models/sentiment-$TIMESTAMP"
          
          if [ "$TRAINING_MODE" = "incremental" ]; then
            if huggingface-cli repo info "$SENTIMENT_MODEL" >/dev/null 2>&1; then
              echo "📥 Found existing sentiment model, using incremental mode"
              python scripts/finetune.py \
                --dataset "$DATASET_FILE" \
                --target-column label \
                --output_dir "$SENTIMENT_OUTPUT" \
                --incremental --baseline-model "$SENTIMENT_MODEL" \
                --push --hub_id "$SENTIMENT_MODEL" \
                $COMMON_ARGS
            else
              echo "🆕 Creating new sentiment model"
              python scripts/finetune.py \
                --dataset "$DATASET_FILE" \
                --target-column label \
                --output_dir "$SENTIMENT_OUTPUT" \
                --model_name "$FALLBACK_MODEL" \
                --push --hub_id "$SENTIMENT_MODEL" \
                $COMMON_ARGS
            fi
          else
            # Mode fresh
            python scripts/finetune.py \
              --dataset "$DATASET_FILE" \
              --target-column label \
              --output_dir "$SENTIMENT_OUTPUT" \
              --model_name "$FALLBACK_MODEL" \
              --push --hub_id "$SENTIMENT_MODEL" \
              $COMMON_ARGS
          fi
          
          MODELS_TRAINED=$((MODELS_TRAINED + 1))
          SENTIMENT_UPDATED=true
          echo "✅ Sentiment model completed"
        fi
        
        # Entraîner le modèle d'importance si disponible
        if [ "$HAS_IMPORTANCE" = "true" ]; then
          echo "🎯 Training importance model..."
          IMPORTANCE_OUTPUT="models/importance-$TIMESTAMP"
          
          if [ "$TRAINING_MODE" = "incremental" ]; then
            if huggingface-cli repo info "$IMPORTANCE_MODEL" >/dev/null 2>&1; then
              echo "📥 Found existing importance model, using incremental mode"
              python scripts/finetune.py \
                --dataset "$DATASET_FILE" \
                --target-column importance \
                --output_dir "$IMPORTANCE_OUTPUT" \
                --incremental --baseline-model "$IMPORTANCE_MODEL" \
                --push --hub_id "$IMPORTANCE_MODEL" \
                $COMMON_ARGS
            else
              echo "🆕 Creating new importance model"
              python scripts/finetune.py \
                --dataset "$DATASET_FILE" \
                --target-column importance \
                --output_dir "$IMPORTANCE_OUTPUT" \
                --model_name "$FALLBACK_MODEL" \
                --push --hub_id "$IMPORTANCE_MODEL" \
                $COMMON_ARGS
            fi
          else
            # Mode fresh
            python scripts/finetune.py \
              --dataset "$DATASET_FILE" \
              --target-column importance \
              --output_dir "$IMPORTANCE_OUTPUT" \
              --model_name "$FALLBACK_MODEL" \
              --push --hub_id "$IMPORTANCE_MODEL" \
              $COMMON_ARGS
          fi
          
          MODELS_TRAINED=$((MODELS_TRAINED + 1))
          IMPORTANCE_UPDATED=true
          echo "✅ Importance model completed"
        fi
        
        if [ $MODELS_TRAINED -eq 0 ]; then
          echo "❌ No valid training columns found"
          exit 1
        fi
        
        # Outputs
        echo "models-trained=$MODELS_TRAINED" >> $GITHUB_OUTPUT
        echo "sentiment-updated=$SENTIMENT_UPDATED" >> $GITHUB_OUTPUT
        echo "importance-updated=$IMPORTANCE_UPDATED" >> $GITHUB_OUTPUT
        
        echo "🎉 Multi-model training completed: $MODELS_TRAINED models"

    - name: 🏷️ Create Version Tag
      if: success()
      run: |
        set -euo pipefail
        
        TAG_NAME="multi-model-v$TIMESTAMP"
        
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        
        TAG_MESSAGE="🚀 Multi-Model Update: $TRAINING_STRATEGY

        📊 Training Results:
        - Dataset: $DATASET
        - Strategy: $TRAINING_STRATEGY
        - Models trained: ${{ steps.training.outputs.models-trained }}
        - Sentiment updated: ${{ steps.training.outputs.sentiment-updated }}
        - Importance updated: ${{ steps.training.outputs.importance-updated }}
        - Timestamp: $TIMESTAMP
        - Commit: ${{ github.sha }}

        🔗 Models:
        $([ "${{ steps.training.outputs.sentiment-updated }}" = "true" ] && echo "- Sentiment: https://huggingface.co/$SENTIMENT_MODEL")
        $([ "${{ steps.training.outputs.importance-updated }}" = "true" ] && echo "- Importance: https://huggingface.co/$IMPORTANCE_MODEL")

        🤖 Generated by TradePulse ML Smart Pipeline"
        
        git tag -a "$TAG_NAME" -m "$TAG_MESSAGE"
        git push origin "$TAG_NAME"
        
        echo "✅ Created version tag: $TAG_NAME"

    - name: 📊 Smart Final Summary
      if: always()
      run: |
        set -euo pipefail
        
        echo "🧠 TradePulse ML - Smart Multi-Model Training Summary"
        echo "=================================================="
        echo "🕐 Timestamp: $(date -u +"%Y-%m-%d %H:%M:%S UTC")"
        echo "🎯 Strategy: $TRAINING_STRATEGY"
        echo "🤖 Models trained: ${{ steps.training.outputs.models-trained }}"
        echo "📊 Dataset: $DATASET"
        echo ""
        
        if [ "${{ steps.training.outputs.sentiment-updated }}" = "true" ]; then
          echo "✅ Sentiment Model:"
          echo "  😊 URL: https://huggingface.co/$SENTIMENT_MODEL"
          echo "  🏷️ Labels: positive, negative, neutral"
        fi
        
        if [ "${{ steps.training.outputs.importance-updated }}" = "true" ]; then
          echo "✅ Importance Model:"
          echo "  🎯 URL: https://huggingface.co/$IMPORTANCE_MODEL"
          echo "  🏷️ Labels: générale, importante, critique"
        fi
        
        echo ""
        echo "💡 Integration in TradePulse:"
        if [ "${{ steps.training.outputs.sentiment-updated }}" = "true" ]; then
          echo "  SENTIMENT_MODEL = \"$SENTIMENT_MODEL\""
        fi
        if [ "${{ steps.training.outputs.importance-updated }}" = "true" ]; then
          echo "  IMPORTANCE_MODEL = \"$IMPORTANCE_MODEL\""
        fi
        echo ""
        echo "🔄 Next: Use HTML editor to retrain with new data!"

    - name: 📤 Upload Training Artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: multi-model-training-${{ github.run_id }}
        path: |
          models/**
          training_strategy.json
          pre_training_validation.json
          finetune.log
        retention-days: 30
