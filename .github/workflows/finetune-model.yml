name: ğŸ¤– TradePulse FinBERT - Auto-Detection Multi-ModÃ¨les

# ğŸ” PERMISSIONS REQUISES POUR RELEASES
permissions:
  contents: write      # Pour crÃ©er des releases et tags
  actions: read        # Pour lire les workflows
  issues: write        # Pour commenter sur les issues/PRs
  pull-requests: write # Pour commenter sur les PRs

# ğŸ¯ CONCURRENCY - Ã‰viter les runs en parallÃ¨le
concurrency:
  group: finetune-${{ github.ref }}
  cancel-in-progress: true

on:
  # DÃ©clenchement manuel avec paramÃ¨tres
  workflow_dispatch:
    inputs:
      dataset:
        description: 'Dataset filename (in datasets/ folder)'
        required: true
        default: 'auto-latest'
        type: string
      
      mode:
        description: 'Training mode'
        required: true
        default: 'incremental'
        type: choice
        options:
          - 'incremental'      # AmÃ©liore le modÃ¨le existant (RECOMMANDÃ‰)
          - 'fresh'            # Repart du modÃ¨le de base
          - 'test'             # Test local seulement
      
      epochs:
        description: 'Number of training epochs'
        required: true
        default: '3'
        type: string
      
      learning_rate:
        description: 'Learning rate'
        required: true
        default: '2e-5'
        type: string
      
      force_update:
        description: 'Force update even without improvement'
        required: false
        default: true
        type: boolean

  # âœ… DÃ‰CLENCHEMENT AUTO - Sur tout commit main (plus de filtre restrictif)
  push:
    branches: [main]
      
  # DÃ©clenchement aprÃ¨s succÃ¨s du Quality Gate (pour PRs)
  workflow_run:
    workflows: ["ğŸ” Dataset Quality Gate"]
    types:
      - completed
    branches: [main]

env:
  # ğŸ¯ MODÃˆLES SPÃ‰CIALISÃ‰S - Auto-dÃ©tection
  SENTIMENT_MODEL: "Bencode92/tradepulse-finbert-sentiment"
  IMPORTANCE_MODEL: "Bencode92/tradepulse-finbert-importance" 
  FALLBACK_MODEL: "yiyanghkust/finbert-tone"

jobs:
  # Job de vÃ©rification des prÃ©requis
  check-prerequisites:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    
    outputs:
      should-run: ${{ steps.check.outputs.should-run }}
      trigger-reason: ${{ steps.check.outputs.trigger-reason }}
      dataset-changed: ${{ steps.check.outputs.dataset-changed }}
      training-mode: ${{ steps.check.outputs.training-mode }}
      
    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 2  # Pour comparer avec le commit prÃ©cÃ©dent
    
    - name: ğŸ” Check Prerequisites & Determine Mode (SIMPLIFIÃ‰)
      id: check
      run: |
        set -euo pipefail
        
        SHOULD_RUN=false
        TRIGGER_REASON=""
        DATASET_CHANGED=false
        TRAINING_MODE="incremental"  # Mode par dÃ©faut
        
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          SHOULD_RUN=true
          TRIGGER_REASON="Manual trigger"
          TRAINING_MODE="${{ github.event.inputs.mode }}"
          
          echo "ğŸ¯ Manual mode selected: $TRAINING_MODE"
          
        elif [ "${{ github.event_name }}" = "push" ]; then
          # âœ… SIMPLIFIÃ‰ - DÃ©clenche sur tout commit main
          SHOULD_RUN=true
          TRIGGER_REASON="Commit on main branch"
          DATASET_CHANGED=true      # On suppose qu'on veut toujours cumuler
          TRAINING_MODE="incremental"
          
          echo "ğŸš€ Auto-trigger activÃ© sur commit main"
          
        elif [ "${{ github.event_name }}" = "workflow_run" ]; then
          # VÃ©rifier si le Quality Gate a rÃ©ussi
          if [ "${{ github.event.workflow_run.conclusion }}" = "success" ]; then
            SHOULD_RUN=true
            TRIGGER_REASON="Quality Gate passed"
            DATASET_CHANGED=true
            TRAINING_MODE="incremental"
          else
            echo "âš ï¸ Quality Gate failed, skipping fine-tuning"
          fi
        fi
        
        echo "should-run=$SHOULD_RUN" >> $GITHUB_OUTPUT
        echo "trigger-reason=$TRIGGER_REASON" >> $GITHUB_OUTPUT  
        echo "dataset-changed=$DATASET_CHANGED" >> $GITHUB_OUTPUT
        echo "training-mode=$TRAINING_MODE" >> $GITHUB_OUTPUT
        
        echo "ğŸ” Prerequisites check:"
        echo "  Should run: $SHOULD_RUN"
        echo "  Reason: $TRIGGER_REASON"
        echo "  Dataset changed: $DATASET_CHANGED"
        echo "  Training mode: $TRAINING_MODE"

  finetune:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # 2 heures max
    needs: check-prerequisites
    if: needs.check-prerequisites.outputs.should-run == 'true'
    
    # ğŸ”§ FIX: Job-level env pour propager HF_TOKEN ET PYTHONPATH dans tous les steps
    env:
      HF_TOKEN: ${{ secrets.HF_TOKEN }}
      PYTHONPATH: ${{ github.workspace }}
    
    outputs:
      models-trained: ${{ steps.training.outputs.models-trained }}
      sentiment-updated: ${{ steps.training.outputs.sentiment-updated }}
      importance-updated: ${{ steps.training.outputs.importance-updated }}
      training-strategy: ${{ steps.detect.outputs.training-strategy }}

    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4
      with:
        lfs: true
        fetch-depth: 2
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: ğŸ Setup Python 3.9
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'

    - name: ğŸ”§ Apply Multi-Label Dimensions Fix
      run: |
        set -euo pipefail
        
        echo "ğŸ”§ Applying ignore_mismatched_sizes fix for multi-label models..."
        
        # Fix pour le mode incrÃ©mental
        sed -i '/problem_type="multi_label_classification"/{
          a\                        ignore_mismatched_sizes=True,
        }' scripts/finetune.py
        
        echo "âœ… Multi-label dimensions fix applied!"

    - name: ğŸ”§ Smart Configuration
      id: config
      run: |
        set -euo pipefail
        
        # DÃ©terminer le dataset
        TRAINING_MODE="${{ needs.check-prerequisites.outputs.training-mode }}"
        
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          MANUAL_DATASET="${{ github.event.inputs.dataset }}"
          
          if [ "$MANUAL_DATASET" = "auto-latest" ]; then
            LATEST_CSV=$(find datasets/ -name "*.csv" -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f2- | xargs basename)
            if [ -z "$LATEST_CSV" ]; then
              echo "âŒ No CSV files found in datasets/"
              exit 1
            fi
            DATASET="$LATEST_CSV"
          else
            DATASET="$MANUAL_DATASET"
          fi
          
          EPOCHS="${{ github.event.inputs.epochs }}"
          LEARNING_RATE="${{ github.event.inputs.learning_rate }}"
          FORCE_UPDATE="${{ github.event.inputs.force_update }}"
        else
          # Auto-trigger: sÃ©lectionner le dernier dataset modifiÃ©
          DATASET_FILE=$(find datasets/ -name "*.csv" -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f2- | xargs basename)
          if [ -z "$DATASET_FILE" ]; then
            echo "âŒ No suitable dataset found"
            exit 1
          fi
          
          DATASET="$DATASET_FILE"
          EPOCHS="3"
          LEARNING_RATE="2e-5"
          FORCE_UPDATE="true"
        fi
        
        # Export des variables
        {
          echo "DATASET=$DATASET"
          echo "EPOCHS=$EPOCHS"
          echo "LEARNING_RATE=$LEARNING_RATE"
          echo "FORCE_UPDATE=$FORCE_UPDATE"
          echo "TRAINING_MODE=$TRAINING_MODE"
        } >> "$GITHUB_ENV"
        
        echo "ğŸ”§ Configuration:"
        echo "  Dataset: $DATASET"
        echo "  Training Mode: $TRAINING_MODE"
        echo "  Epochs: $EPOCHS"
        echo "  Learning Rate: $LEARNING_RATE"
        echo "  Force Update: $FORCE_UPDATE"
        echo "  PYTHONPATH: $PYTHONPATH"

    - name: ğŸ“¦ Install Dependencies
      run: |
        set -euo pipefail
        
        python -m pip install --upgrade pip
        pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
        pip install "transformers[torch]==4.41.0" datasets==2.19.1 accelerate==0.30.1 evaluate==0.4.2
        pip install scikit-learn==1.4.2 pandas==2.2.2 numpy==1.26.4
        pip install tensorboard==2.16.2
        
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        fi

    - name: ğŸ” Setup HuggingFace Token (VALIDATION)
      run: |
        set -euo pipefail
        
        if [ -z "$HF_TOKEN" ]; then
          echo "âŒ HF_TOKEN required for model updates"
          echo "ğŸ’¡ CrÃ©ez un token Write sur https://huggingface.co/settings/tokens"
          exit 1
        fi
        
        # ğŸ”§ CORRECTION: Ajouter --add-to-git-credential pour Git LFS
        huggingface-cli login --token "$HF_TOKEN" \
          --add-to-git-credential
        
        echo "âœ… HuggingFace authentication successful"
        
        # VÃ©rification des permissions
        if huggingface-cli whoami; then
          echo "âœ… Token Write validÃ©"
        else
          echo "âŒ Token invalide"
          exit 1
        fi
        
        # ğŸ”§ DEBUG: VÃ©rifier que le token est accessible pour les scripts Python
        echo "ğŸ” Token disponible pour Python: $(python -c "import os; print('âœ…' if os.environ.get('HF_TOKEN') else 'âŒ')")"
        echo "ğŸ” PYTHONPATH disponible: $(python -c "import os; print('âœ…' if os.environ.get('PYTHONPATH') else 'âŒ')")"

    - name: ğŸ” Validate Dataset Quality
      run: |
        set -euo pipefail
        
        DATASET_FILE="datasets/$DATASET"
        echo "ğŸ§ª Validating dataset quality: $DATASET_FILE"
        
        if [ ! -f "$DATASET_FILE" ]; then
          echo "âŒ Dataset file not found: $DATASET_FILE"
          exit 1
        fi
        
        if [ -f "scripts/validate_dataset.py" ]; then
          if python scripts/validate_dataset.py "$DATASET_FILE" --output-json "pre_training_validation.json"; then
            echo "âœ… Dataset validation passed!"
          else
            echo "âŒ Dataset validation failed!"
            exit 1
          fi
        fi

    - name: ğŸ§  Smart Column Detection & Training Strategy
      id: detect
      run: |
        set -euo pipefail
        
        # CrÃ©er le script d'auto-dÃ©tection
        cat > scripts/auto_detect_columns.py << 'EOF'
        #!/usr/bin/env python3
        import pandas as pd
        import json
        import sys
        from pathlib import Path
        
        def detect_training_columns(dataset_path):
            if dataset_path.suffix.lower() == '.csv':
                df = pd.read_csv(dataset_path)
            else:
                df = pd.read_json(dataset_path)
            
            columns = set(df.columns.str.lower())
            has_label = 'label' in columns
            has_importance = 'importance' in columns
            has_correlations = 'correlations' in columns
            sample_size = len(df)
            
            # Nouvelle logique incluant les corrÃ©lations
            if has_label and has_importance and has_correlations and sample_size >= 50:
                strategy = 'triple_model'
                models = [
                    {'target': 'sentiment', 'column': 'label'},
                    {'target': 'importance', 'column': 'importance'},
                    {'target': 'correlations', 'column': 'correlations'}
                ]
            elif has_label and has_importance and sample_size >= 30:
                strategy = 'dual_model'
                models = [
                    {'target': 'sentiment', 'column': 'label'},
                    {'target': 'importance', 'column': 'importance'}
                ]
            elif has_label:
                strategy = 'sentiment_only'
                models = [{'target': 'sentiment', 'column': 'label'}]
            elif has_importance:
                strategy = 'importance_only'
                models = [{'target': 'importance', 'column': 'importance'}]
            elif has_correlations:
                strategy = 'correlations_only'
                models = [{'target': 'correlations', 'column': 'correlations'}]
            else:
                strategy = 'error'
                models = []
            
            return {
                'strategy': strategy,
                'models': models,
                'sample_size': sample_size,
                'has_label': has_label,
                'has_importance': has_importance,
                'has_correlations': has_correlations
            }
        
        if __name__ == "__main__":
            result = detect_training_columns(Path(sys.argv[1]))
            print(json.dumps(result))
        EOF
        
        DATASET_FILE="datasets/$DATASET"
        echo "ğŸ§  Analyzing dataset structure: $DATASET_FILE"
        
        # Analyser le dataset
        DETECTION_RESULT=$(python scripts/auto_detect_columns.py "$DATASET_FILE")
        echo "$DETECTION_RESULT" > training_strategy.json
        
        STRATEGY=$(echo "$DETECTION_RESULT" | jq -r '.strategy')
        MODELS_COUNT=$(echo "$DETECTION_RESULT" | jq -r '.models | length')
        HAS_LABEL=$(echo "$DETECTION_RESULT" | jq -r '.has_label')
        HAS_IMPORTANCE=$(echo "$DETECTION_RESULT" | jq -r '.has_importance')
        HAS_CORRELATIONS=$(echo "$DETECTION_RESULT" | jq -r '.has_correlations')
        
        echo "ğŸ¯ Detected strategy: $STRATEGY"
        echo "ğŸ¤– Models to train: $MODELS_COUNT"
        echo "ğŸ˜Š Has sentiment: $HAS_LABEL"
        echo "ğŸ¯ Has importance: $HAS_IMPORTANCE"
        echo "ğŸŒ Has correlations: $HAS_CORRELATIONS"
        
        # Exporter les variables
        echo "TRAINING_STRATEGY=$STRATEGY" >> $GITHUB_ENV
        echo "HAS_LABEL=$HAS_LABEL" >> $GITHUB_ENV
        echo "HAS_IMPORTANCE=$HAS_IMPORTANCE" >> $GITHUB_ENV
        echo "HAS_CORRELATIONS=$HAS_CORRELATIONS" >> $GITHUB_ENV
        echo "training-strategy=$STRATEGY" >> $GITHUB_OUTPUT
        
        # CrÃ©er les rÃ©pertoires de sortie
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        echo "TIMESTAMP=$TIMESTAMP" >> $GITHUB_ENV

    - name: ğŸ¤– Train Multi-Model Strategy (FULL FIX)
      id: training
      run: |
        set -euo pipefail
        
        echo "ğŸš€ Auto-Training Mode - ALL FIXES Applied!"
        echo "ğŸ“‹ Strategy: $TRAINING_STRATEGY"
        echo "ğŸ¯ Training Mode: $TRAINING_MODE"
        
        # ğŸ”§ CORRECTION CRITIQUE: Mapping TRAINING_MODE â†’ EXEC_MODE
        if [ "$TRAINING_MODE" = "test" ]; then
          EXEC_MODE="test"
          echo "ğŸ§ª Mode test: pas de push HuggingFace"
        else
          EXEC_MODE="production"
          echo "ğŸš€ Mode production: push HuggingFace activÃ©"
        fi
        
        DATASET_FILE="datasets/$DATASET"
        MODELS_TRAINED=0
        SENTIMENT_UPDATED=false
        IMPORTANCE_UPDATED=false
        CORRELATIONS_UPDATED=false
        
        # Arguments communs avec mapping correct
        COMMON_ARGS="--epochs $EPOCHS --lr $LEARNING_RATE --mode $EXEC_MODE --force-update"
        
        # EntraÃ®ner le modÃ¨le de sentiment si disponible
        if [ "$HAS_LABEL" = "true" ]; then
          echo "ğŸ˜Š Training sentiment model..."
          SENTIMENT_OUTPUT="models/sentiment-$TIMESTAMP"
          
          if [ "$TRAINING_MODE" = "incremental" ]; then
            python scripts/finetune.py \
              --dataset "$DATASET_FILE" \
              --target-column label \
              --output_dir "$SENTIMENT_OUTPUT" \
              --incremental \
              --baseline-model "$SENTIMENT_MODEL" \
              --push --hub_id "$SENTIMENT_MODEL" \
              $COMMON_ARGS
          else
            python scripts/finetune.py \
              --dataset "$DATASET_FILE" \
              --target-column label \
              --output_dir "$SENTIMENT_OUTPUT" \
              --model_name "$FALLBACK_MODEL" \
              --push --hub_id "$SENTIMENT_MODEL" \
              $COMMON_ARGS
          fi
          
          MODELS_TRAINED=$((MODELS_TRAINED + 1))
          SENTIMENT_UPDATED=true
          echo "âœ… Sentiment model training completed!"
        fi
        
        # EntraÃ®ner le modÃ¨le d'importance si disponible
        if [ "$HAS_IMPORTANCE" = "true" ]; then
          echo "ğŸ¯ Training importance model..."
          IMPORTANCE_OUTPUT="models/importance-$TIMESTAMP"
          
          if [ "$TRAINING_MODE" = "incremental" ]; then
            python scripts/finetune.py \
              --dataset "$DATASET_FILE" \
              --target-column importance \
              --output_dir "$IMPORTANCE_OUTPUT" \
              --incremental \
              --baseline-model "$IMPORTANCE_MODEL" \
              --push --hub_id "$IMPORTANCE_MODEL" \
              $COMMON_ARGS
          else
            python scripts/finetune.py \
              --dataset "$DATASET_FILE" \
              --target-column importance \
              --output_dir "$IMPORTANCE_OUTPUT" \
              --model_name "$FALLBACK_MODEL" \
              --push --hub_id "$IMPORTANCE_MODEL" \
              $COMMON_ARGS
          fi
          
          MODELS_TRAINED=$((MODELS_TRAINED + 1))
          IMPORTANCE_UPDATED=true
          echo "âœ… Importance model training completed!"
        fi
        
        # ğŸŒ EntraÃ®ner le modÃ¨le de corrÃ©lations si disponible
        if [ "$HAS_CORRELATIONS" = "true" ]; then
          echo "ğŸŒ Training correlations model..."
          CORRELATIONS_OUTPUT="models/correlations-$TIMESTAMP"
          CORRELATIONS_MODEL="Bencode92/tradepulse-finbert-correlations"
          
          if [ "$TRAINING_MODE" = "incremental" ]; then
            python scripts/finetune.py \
              --dataset "$DATASET_FILE" \
              --target-column correlations \
              --output_dir "$CORRELATIONS_OUTPUT" \
              --incremental \
              --baseline-model "$CORRELATIONS_MODEL" \
              --push --hub_id "$CORRELATIONS_MODEL" \
              $COMMON_ARGS
          else
            python scripts/finetune.py \
              --dataset "$DATASET_FILE" \
              --target-column correlations \
              --output_dir "$CORRELATIONS_OUTPUT" \
              --model_name "$FALLBACK_MODEL" \
              --push --hub_id "$CORRELATIONS_MODEL" \
              $COMMON_ARGS
          fi
          
          MODELS_TRAINED=$((MODELS_TRAINED + 1))
          CORRELATIONS_UPDATED=true
          echo "âœ… Correlations model training completed!"
        fi
        
        if [ $MODELS_TRAINED -eq 0 ]; then
          echo "âŒ No valid training columns found"
          exit 1
        fi
        
        # Outputs
        echo "models-trained=$MODELS_TRAINED" >> $GITHUB_OUTPUT
        echo "sentiment-updated=$SENTIMENT_UPDATED" >> $GITHUB_OUTPUT
        echo "importance-updated=$IMPORTANCE_UPDATED" >> $GITHUB_OUTPUT
        echo "correlations-updated=$CORRELATIONS_UPDATED" >> $GITHUB_OUTPUT
        
        echo "ğŸ‰ TRAINING COMPLETED: $MODELS_TRAINED models!"

    - name: ğŸ“Š Final Summary
      if: always()
      run: |
        echo "ğŸš€ TradePulse ML - ALL FIXES APPLIED"
        echo "===================================="
        echo "âœ… PYTHONPATH: ${{ github.workspace }}"
        echo "âœ… HF_TOKEN: Available"
        echo "âœ… ignore_mismatched_sizes: Applied"
        echo ""
        echo "ğŸ”§ FIXES APPLIED:"
        echo "  âœ… Job-level PYTHONPATH"
        echo "  âœ… Job-level HF_TOKEN"
        echo "  âœ… Multi-label dimensions fix"
        echo "  âœ… No more os.chdir()"
        echo ""
        if [ "${{ steps.training.outputs.correlations-updated }}" = "true" ]; then
          echo "ğŸŒ Correlations Model:"
          echo "  âœ… 125 labels (commodities)"
          echo "  âœ… Multi-label classification"
          echo "  âœ… ignore_mismatched_sizes=True"
        fi

    - name: ğŸ“¤ Upload Training Artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: training-${{ github.run_id }}
        path: |
          models/**
          training_strategy.json
          pre_training_validation.json
          finetune.log
        retention-days: 30
