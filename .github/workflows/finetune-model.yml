name: ğŸ¤– TradePulse FinBERT Fine-tuning

on:
  # DÃ©clenchement manuel avec paramÃ¨tres
  workflow_dispatch:
    inputs:
      dataset:
        description: 'Dataset filename (in datasets/ folder)'
        required: true
        default: 'auto-latest'
        type: string
      
      model_name:
        description: 'Base model to fine-tune'
        required: true
        default: 'yiyanghkust/finbert-tone'
        type: choice
        options:
          - 'yiyanghkust/finbert-tone'
          - 'ProsusAI/finbert'
          - 'nlptown/bert-base-multilingual-uncased-sentiment'
      
      epochs:
        description: 'Number of training epochs'
        required: true
        default: '3'
        type: string
      
      learning_rate:
        description: 'Learning rate'
        required: true
        default: '2e-5'
        type: string
      
      push_to_hub:
        description: 'Push model to HuggingFace Hub'
        required: true
        default: false
        type: boolean

  # DÃ©clenchement sur push dans datasets/ (aprÃ¨s validation quality gate)
  push:
    paths:
      - 'datasets/**.csv'
      - 'datasets/**.json'
      - 'scripts/finetune.py'

jobs:
  finetune:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # 2 heures max

    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4
      with:
        lfs: true

    - name: ğŸ Setup Python 3.9
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'

    - name: ğŸ”§ Smart Dataset Selection
      run: |
        echo "ğŸ¯ Selecting dataset for training..."
        
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          MANUAL_DATASET="${{ github.event.inputs.dataset }}"
          
          if [ "$MANUAL_DATASET" = "auto-latest" ]; then
            echo "ğŸ” Auto-selecting latest dataset..."
            # SÃ©lectionner le dernier CSV ajoutÃ© (par date de modification)
            LATEST_CSV=$(find datasets/ -name "*.csv" -type f -exec ls -t {} + | head -1 | xargs basename)
            if [ -z "$LATEST_CSV" ]; then
              echo "âŒ No CSV files found in datasets/"
              exit 1
            fi
            echo "DATASET=$LATEST_CSV" >> $GITHUB_ENV
            echo "ğŸ“Š Auto-selected dataset: $LATEST_CSV"
          else
            echo "DATASET=$MANUAL_DATASET" >> $GITHUB_ENV
            echo "ğŸ“Š Manual dataset: $MANUAL_DATASET"
          fi
          
          echo "MODEL_NAME=${{ github.event.inputs.model_name }}" >> $GITHUB_ENV
          echo "EPOCHS=${{ github.event.inputs.epochs }}" >> $GITHUB_ENV
          echo "LEARNING_RATE=${{ github.event.inputs.learning_rate }}" >> $GITHUB_ENV
          echo "PUSH_TO_HUB=${{ github.event.inputs.push_to_hub }}" >> $GITHUB_ENV
        else
          # DÃ©clenchement automatique aprÃ¨s push
          echo "ğŸ”„ Auto-trigger mode: selecting latest dataset..."
          
          # Trouver le dernier dataset modifiÃ©/ajoutÃ©
          CHANGED_DATASETS=$(git diff --name-only HEAD~1 HEAD | grep -E '^datasets/.*\.(csv|json)$' || true)
          
          if [ -n "$CHANGED_DATASETS" ]; then
            # Prendre le premier dataset modifiÃ©
            DATASET_FILE=$(echo "$CHANGED_DATASETS" | head -1 | xargs basename)
            echo "ğŸ“ Using modified dataset: $DATASET_FILE"
          else
            # Fallback: prendre le plus rÃ©cent CSV
            DATASET_FILE=$(find datasets/ -name "*.csv" -type f -exec ls -t {} + | head -1 | xargs basename)
            echo "ğŸ“Š Using latest available dataset: $DATASET_FILE"
          fi
          
          if [ -z "$DATASET_FILE" ]; then
            echo "âŒ No suitable dataset found"
            exit 1
          fi
          
          echo "DATASET=$DATASET_FILE" >> $GITHUB_ENV
          echo "MODEL_NAME=yiyanghkust/finbert-tone" >> $GITHUB_ENV
          echo "EPOCHS=3" >> $GITHUB_ENV
          echo "LEARNING_RATE=2e-5" >> $GITHUB_ENV
          echo "PUSH_TO_HUB=false" >> $GITHUB_ENV
        fi
        
        echo ""
        echo "ğŸ”§ Final configuration:"
        echo "  Trigger: ${{ github.event_name }}"
        echo "  Dataset: $DATASET"
        echo "  Model: $MODEL_NAME"
        echo "  Epochs: $EPOCHS"
        echo "  Learning Rate: $LEARNING_RATE"
        echo "  Push to Hub: $PUSH_TO_HUB"

    - name: ğŸ“¦ Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip cache purge
        pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
        pip install "transformers[torch]==4.41.0" datasets==2.19.1 accelerate==0.30.1 evaluate==0.4.2
        pip install scikit-learn==1.4.2 pandas==2.2.2 numpy==1.26.4
        pip install huggingface_hub==0.23.0 tensorboard==2.16.2
        
        if [ -f requirements.txt ]; then
          echo "ğŸ“‹ Installing additional requirements..."
          pip install -r requirements.txt
        fi
        
        # â”€â”€ VÃ©rifications de version â”€â”€
        python - <<'PY'
        import transformers, torch, datasets, sys
        print(f"âœ… Transformers: {transformers.__version__}")
        print(f"âœ… PyTorch: {torch.__version__}")
        print(f"âœ… Datasets: {datasets.__version__}")
        
        from transformers import TrainingArguments
        try:
            TrainingArguments(output_dir="/tmp", evaluation_strategy="epoch")
            print("âœ… evaluation_strategy parameter supported")
        except Exception as e:
            print(f"âŒ evaluation_strategy error: {e}")
            sys.exit(1)
        PY

    - name: ğŸ” Setup HuggingFace Token
      if: env.PUSH_TO_HUB == 'true'
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
      run: |
        if [ -z "$HF_TOKEN" ]; then
          echo "âŒ HF_TOKEN required for push_to_hub=true"
          echo "ğŸ’¡ Add HF_TOKEN to repository secrets in Settings > Secrets"
          exit 1
        fi
        
        huggingface-cli login --token "$HF_TOKEN"
        echo "âœ… HuggingFace authentication successful"
        
        # VÃ©rification de l'authentification
        huggingface-cli whoami || {
          echo "âŒ HuggingFace authentication failed"
          exit 1
        }

    - name: ğŸ” Validate Dataset Quality
      run: |
        DATASET_FILE="datasets/$DATASET"
        echo "ğŸ§ª Validating dataset quality: $DATASET_FILE"
        
        if [ ! -f "$DATASET_FILE" ]; then
          echo "âŒ Dataset file not found: $DATASET_FILE"
          echo "ğŸ“ Available files in datasets/:"
          find datasets/ -name "*.csv" -o -name "*.json" | head -10
          exit 1
        fi
        
        echo "âœ… Dataset file found: $DATASET_FILE"
        echo "ğŸ“Š File size: $(du -h "$DATASET_FILE" | cut -f1)"
        
        # Utiliser notre script de validation
        if [ -f "scripts/validate_dataset.py" ]; then
          echo "ğŸ” Running comprehensive validation..."
          python scripts/validate_dataset.py "$DATASET_FILE" || {
            echo "âŒ Dataset validation failed!"
            echo "ğŸ’¡ Fix the issues above before proceeding with training"
            exit 1
          }
          echo "âœ… Dataset validation passed!"
        else
          echo "âš ï¸ Validation script not found, using basic checks..."
          # Validation basique pour compatibilitÃ©
          echo "ğŸ‘€ Dataset preview:"
          head -3 "$DATASET_FILE"
          
          if [[ "$DATASET_FILE" == *.csv ]]; then
            if ! head -1 "$DATASET_FILE" | grep -q "text.*label"; then
              echo "âš ï¸ CSV header should contain 'text' and 'label' columns"
              echo "ğŸ“‹ Current header: $(head -1 "$DATASET_FILE")"
            fi
          fi
        fi

    - name: ğŸ¤– Run Fine-tuning
      run: |
        echo "ğŸš€ Starting FinBERT fine-tuning..."
        echo "ğŸ“‹ Configuration:"
        echo "  Dataset: $DATASET"
        echo "  Model: $MODEL_NAME"
        echo "  Epochs: $EPOCHS"
        echo "  Learning Rate: $LEARNING_RATE"
        echo "  Push to Hub: $PUSH_TO_HUB"
        
        OUTPUT_DIR="models/finbert-$(date +%Y%m%d_%H%M%S)"
        mkdir -p "$OUTPUT_DIR"
        echo "ğŸ“ Output directory: $OUTPUT_DIR"
        
        ARGS="--dataset datasets/$DATASET --output_dir $OUTPUT_DIR --model_name $MODEL_NAME --epochs $EPOCHS --lr $LEARNING_RATE"
        
        if [ "$PUSH_TO_HUB" = "true" ]; then
          HUB_ID="Bencode92/tradepulse-finbert-$(date +%Y%m%d-%H%M)"
          ARGS="$ARGS --push --hub_id $HUB_ID"
          echo "ğŸš€ Will push to HuggingFace Hub as: $HUB_ID"
        fi
        
        echo "ğŸ”¥ Launching training with args: $ARGS"
        
        python scripts/finetune.py $ARGS || {
          echo "âŒ Training failed, showing logs..."
          [ -f finetune.log ] && tail -20 finetune.log
          exit 1
        }
        
        echo "âœ… Training completed successfully!"

    - name: ğŸ“ˆ Training Summary
      if: always()
      run: |
        echo "ğŸ“Š Training Summary:"
        echo "===================="
        
        if find models/ -name "training_report.json" -type f | head -1 | grep -q .; then
          echo "ğŸ“„ Training reports found:"
          find models/ -name "training_report.json" -exec echo "  ğŸ“‹ {}" \;
          echo ""
          echo "ğŸ“ˆ Latest training metrics:"
          find models/ -name "training_report.json" -exec cat {} \; | head -50
        else
          echo "âš ï¸ No training report found"
        fi
        
        echo ""
        echo "ğŸ“ Generated model directories:"
        find models/ -type d -name "finbert-*" | head -5 || echo "No model directories found"
        
        echo ""
        echo "ğŸ“ Log files:"
        ls -la *.log 2>/dev/null || echo "No log files found"

    - name: ğŸ“¤ Upload Model Artifacts
      if: success()
      uses: actions/upload-artifact@v4
      with:
        name: tradepulse-finbert-${{ github.run_id }}
        path: |
          models/**
          finetune.log
        retention-days: 30

    - name: ğŸ“¤ Upload Logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: training-logs-${{ github.run_id }}
        path: |
          finetune.log
          models/**/logs/**
        retention-days: 7

    - name: ğŸ‰ Success Notification
      if: success()
      run: |
        echo "âœ… Fine-tuning completed successfully!"
        echo "ğŸ” Check the 'Actions' tab for downloadable artifacts"
        echo "ğŸ“Š Model saved in: $(find models/ -type d -name "finbert-*" | head -1)"
        if [ "$PUSH_TO_HUB" = "true" ]; then
          echo "ğŸš€ Model pushed to HuggingFace Hub"
        fi
        
        echo ""
        echo "ğŸ“‹ Final Summary:"
        echo "  Dataset: $DATASET"
        echo "  Model: $MODEL_NAME"
        echo "  Epochs: $EPOCHS"
        echo "  Status: SUCCESS âœ…"
