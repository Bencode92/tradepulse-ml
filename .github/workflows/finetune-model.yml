name: ü§ñ TradePulse FinBERT - Auto-Detection Multi-Mod√®les

# üîê PERMISSIONS REQUISES POUR RELEASES
permissions:
  contents: write      # Pour cr√©er des releases et tags
  actions: read        # Pour lire les workflows
  issues: write        # Pour commenter sur les issues/PRs
  pull-requests: write # Pour commenter sur les PRs

# üéØ CONCURRENCY - √âviter les runs en parall√®le
concurrency:
  group: finetune-${{ github.ref }}
  cancel-in-progress: true

on:
  # D√©clenchement manuel avec param√®tres
  workflow_dispatch:
    inputs:
      dataset:
        description: 'Dataset filename (in datasets/ folder)'
        required: true
        default: 'auto-latest'
        type: string
      
      mode:
        description: 'Training mode'
        required: true
        default: 'incremental'
        type: choice
        options:
          - 'incremental'      # Am√©liore le mod√®le existant (RECOMMAND√â)
          - 'fresh'            # Repart du mod√®le de base
          - 'test'             # Test local seulement
      
      epochs:
        description: 'Number of training epochs'
        required: true
        default: '3'
        type: string
      
      learning_rate:
        description: 'Learning rate'
        required: true
        default: '2e-5'
        type: string
      
      force_update:
        description: 'Force update even without improvement'
        required: false
        default: true
        type: boolean

  # ‚úÖ D√âCLENCHEMENT AUTO - Sur tout commit main (plus de filtre restrictif)
  push:
    branches: [main]
      
  # D√©clenchement apr√®s succ√®s du Quality Gate (pour PRs)
  workflow_run:
    workflows: ["üîç Dataset Quality Gate"]
    types:
      - completed
    branches: [main]

env:
  # üéØ MOD√àLES SP√âCIALIS√âS - Auto-d√©tection
  SENTIMENT_MODEL: "Bencode92/tradepulse-finbert-sentiment"
  IMPORTANCE_MODEL: "Bencode92/tradepulse-finbert-importance" 
  FALLBACK_MODEL: "yiyanghkust/finbert-tone"

jobs:
  # Job de v√©rification des pr√©requis
  check-prerequisites:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    
    outputs:
      should-run: ${{ steps.check.outputs.should-run }}
      trigger-reason: ${{ steps.check.outputs.trigger-reason }}
      dataset-changed: ${{ steps.check.outputs.dataset-changed }}
      training-mode: ${{ steps.check.outputs.training-mode }}
      
    steps:
    - name: üì• Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 2  # Pour comparer avec le commit pr√©c√©dent
    
    - name: üîç Check Prerequisites & Determine Mode (SIMPLIFI√â)
      id: check
      run: |
        set -euo pipefail
        
        SHOULD_RUN=false
        TRIGGER_REASON=""
        DATASET_CHANGED=false
        TRAINING_MODE="incremental"  # Mode par d√©faut
        
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          SHOULD_RUN=true
          TRIGGER_REASON="Manual trigger"
          TRAINING_MODE="${{ github.event.inputs.mode }}"
          
          echo "üéØ Manual mode selected: $TRAINING_MODE"
          
        elif [ "${{ github.event_name }}" = "push" ]; then
          # ‚úÖ SIMPLIFI√â - D√©clenche sur tout commit main
          SHOULD_RUN=true
          TRIGGER_REASON="Commit on main branch"
          DATASET_CHANGED=true      # On suppose qu'on veut toujours cumuler
          TRAINING_MODE="incremental"
          
          echo "üöÄ Auto-trigger activ√© sur commit main"
          
        elif [ "${{ github.event_name }}" = "workflow_run" ]; then
          # V√©rifier si le Quality Gate a r√©ussi
          if [ "${{ github.event.workflow_run.conclusion }}" = "success" ]; then
            SHOULD_RUN=true
            TRIGGER_REASON="Quality Gate passed"
            DATASET_CHANGED=true
            TRAINING_MODE="incremental"
          else
            echo "‚ö†Ô∏è Quality Gate failed, skipping fine-tuning"
          fi
        fi
        
        echo "should-run=$SHOULD_RUN" >> $GITHUB_OUTPUT
        echo "trigger-reason=$TRIGGER_REASON" >> $GITHUB_OUTPUT  
        echo "dataset-changed=$DATASET_CHANGED" >> $GITHUB_OUTPUT
        echo "training-mode=$TRAINING_MODE" >> $GITHUB_OUTPUT
        
        echo "üîç Prerequisites check:"
        echo "  Should run: $SHOULD_RUN"
        echo "  Reason: $TRIGGER_REASON"
        echo "  Dataset changed: $DATASET_CHANGED"
        echo "  Training mode: $TRAINING_MODE"

  finetune:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # 2 heures max
    needs: check-prerequisites
    if: needs.check-prerequisites.outputs.should-run == 'true'
    
    # üîß FIX: Job-level env pour propager HF_TOKEN ET PYTHONPATH dans tous les steps
    env:
      HF_TOKEN: ${{ secrets.HF_TOKEN }}
      PYTHONPATH: ${{ github.workspace }}
    
    outputs:
      models-trained: ${{ steps.training.outputs.models-trained }}
      sentiment-updated: ${{ steps.training.outputs.sentiment-updated }}
      importance-updated: ${{ steps.training.outputs.importance-updated }}
      training-strategy: ${{ steps.detect.outputs.training-strategy }}

    steps:
    - name: üì• Checkout Repository
      uses: actions/checkout@v4
      with:
        lfs: true
        fetch-depth: 2
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: üêç Setup Python 3.9
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'

    - name: üîß Apply Multi-Label Dimensions Fix
      run: |
        set -euo pipefail
        
        echo "üîß Applying ignore_mismatched_sizes fix for multi-label models..."
        
        # Fix pour le mode incr√©mental
        sed -i '/problem_type="multi_label_classification"/{
          a\                        ignore_mismatched_sizes=True,
        }' scripts/finetune.py
        
        echo "‚úÖ Multi-label dimensions fix applied!"

    - name: üîß Smart Configuration
      id: config
      run: |
        set -euo pipefail
        
        # D√©terminer le dataset
        TRAINING_MODE="${{ needs.check-prerequisites.outputs.training-mode }}"
        
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          MANUAL_DATASET="${{ github.event.inputs.dataset }}"
          
          if [ "$MANUAL_DATASET" = "auto-latest" ]; then
            LATEST_CSV=$(find datasets/ -name "*.csv" -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f2- | xargs basename)
            if [ -z "$LATEST_CSV" ]; then
              echo "‚ùå No CSV files found in datasets/"
              exit 1
            fi
            DATASET="$LATEST_CSV"
          else
            DATASET="$MANUAL_DATASET"
          fi
          
          EPOCHS="${{ github.event.inputs.epochs }}"
          LEARNING_RATE="${{ github.event.inputs.learning_rate }}"
          FORCE_UPDATE="${{ github.event.inputs.force_update }}"
        else
          # Auto-trigger: s√©lectionner le dernier dataset modifi√©
          DATASET_FILE=$(find datasets/ -name "*.csv" -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f2- | xargs basename)
          if [ -z "$DATASET_FILE" ]; then
            echo "‚ùå No suitable dataset found"
            exit 1
          fi
          
          DATASET="$DATASET_FILE"
          EPOCHS="3"
          LEARNING_RATE="2e-5"
          FORCE_UPDATE="true"
        fi
        
        # Export des variables
        {
          echo "DATASET=$DATASET"
          echo "EPOCHS=$EPOCHS"
          echo "LEARNING_RATE=$LEARNING_RATE"
          echo "FORCE_UPDATE=$FORCE_UPDATE"
          echo "TRAINING_MODE=$TRAINING_MODE"
        } >> "$GITHUB_ENV"
        
        echo "üîß Configuration:"
        echo "  Dataset: $DATASET"
        echo "  Training Mode: $TRAINING_MODE"
        echo "  Epochs: $EPOCHS"
        echo "  Learning Rate: $LEARNING_RATE"
        echo "  Force Update: $FORCE_UPDATE"
        echo "  PYTHONPATH: $PYTHONPATH"

    - name: üì¶ Install Dependencies
      run: |
        set -euo pipefail
        
        python -m pip install --upgrade pip
        pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
        pip install "transformers[torch]==4.41.0" datasets==2.19.1 accelerate==0.30.1 evaluate==0.4.2
        pip install scikit-learn==1.4.2 pandas==2.2.2 numpy==1.26.4
        pip install tensorboard==2.16.2
        
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        fi

    - name: üîê Setup HuggingFace Token (VALIDATION)
      run: |
        set -euo pipefail
        
        if [ -z "$HF_TOKEN" ]; then
          echo "‚ùå HF_TOKEN required for model updates"
          echo "üí° Cr√©ez un token Write sur https://huggingface.co/settings/tokens"
          exit 1
        fi
        
        # üîß CORRECTION: Ajouter --add-to-git-credential pour Git LFS
        huggingface-cli login --token "$HF_TOKEN" \
          --add-to-git-credential
        
        echo "‚úÖ HuggingFace authentication successful"
        
        # V√©rification des permissions
        if huggingface-cli whoami; then
          echo "‚úÖ Token Write valid√©"
        else
          echo "‚ùå Token invalide"
          exit 1
        fi
        
        # üîß DEBUG: V√©rifier que le token est accessible pour les scripts Python
        echo "üîç Token disponible pour Python: $(python -c "import os; print('‚úÖ' if os.environ.get('HF_TOKEN') else '‚ùå')")"
        echo "üîç PYTHONPATH disponible: $(python -c "import os; print('‚úÖ' if os.environ.get('PYTHONPATH') else '‚ùå')")"

    - name: üîç Validate Dataset Quality
      run: |
        set -euo pipefail
        
        DATASET_FILE="datasets/$DATASET"
        echo "üß™ Validating dataset quality: $DATASET_FILE"
        
        if [ ! -f "$DATASET_FILE" ]; then
          echo "‚ùå Dataset file not found: $DATASET_FILE"
          exit 1
        fi
        
        if [ -f "scripts/validate_dataset.py" ]; then
          if python scripts/validate_dataset.py "$DATASET_FILE" --output-json "pre_training_validation.json"; then
            echo "‚úÖ Dataset validation passed!"
          else
            echo "‚ùå Dataset validation failed!"
            exit 1
          fi
        fi

    - name: üß† Smart Column Detection & Training Strategy
      id: detect
      run: |
        set -euo pipefail
        
        # Cr√©er le script d'auto-d√©tection
        cat > scripts/auto_detect_columns.py << 'EOF'
        #!/usr/bin/env python3
        import pandas as pd
        import json
        import sys
        from pathlib import Path
        
        def detect_training_columns(dataset_path):
            if dataset_path.suffix.lower() == '.csv':
                df = pd.read_csv(dataset_path)
            else:
                df = pd.read_json(dataset_path)
            
            columns = set(df.columns.str.lower())
            has_label = 'label' in columns
            has_importance = 'importance' in columns
            has_correlations = 'correlations' in columns
            sample_size = len(df)
            
            # Nouvelle logique incluant les corr√©lations
            if has_label and has_importance and has_correlations and sample_size >= 50:
                strategy = 'triple_model'
                models = [
                    {'target': 'sentiment', 'column': 'label'},
                    {'target': 'importance', 'column': 'importance'},
                    {'target': 'correlations', 'column': 'correlations'}
                ]
            elif has_label and has_importance and sample_size >= 30:
                strategy = 'dual_model'
                models = [
                    {'target': 'sentiment', 'column': 'label'},
                    {'target': 'importance', 'column': 'importance'}
                ]
            elif has_label:
                strategy = 'sentiment_only'
                models = [{'target': 'sentiment', 'column': 'label'}]
            elif has_importance:
                strategy = 'importance_only'
                models = [{'target': 'importance', 'column': 'importance'}]
            elif has_correlations:
                strategy = 'correlations_only'
                models = [{'target': 'correlations', 'column': 'correlations'}]
            else:
                strategy = 'error'
                models = []
            
            return {
                'strategy': strategy,
                'models': models,
                'sample_size': sample_size,
                'has_label': has_label,
                'has_importance': has_importance,
                'has_correlations': has_correlations
            }
        
        if __name__ == "__main__":
            result = detect_training_columns(Path(sys.argv[1]))
            print(json.dumps(result))
        EOF
        
        DATASET_FILE="datasets/$DATASET"
        echo "üß† Analyzing dataset structure: $DATASET_FILE"
        
        # Analyser le dataset
        DETECTION_RESULT=$(python scripts/auto_detect_columns.py "$DATASET_FILE")
        echo "$DETECTION_RESULT" > training_strategy.json
        
        STRATEGY=$(echo "$DETECTION_RESULT" | jq -r '.strategy')
        MODELS_COUNT=$(echo "$DETECTION_RESULT" | jq -r '.models | length')
        HAS_LABEL=$(echo "$DETECTION_RESULT" | jq -r '.has_label')
        HAS_IMPORTANCE=$(echo "$DETECTION_RESULT" | jq -r '.has_importance')
        HAS_CORRELATIONS=$(echo "$DETECTION_RESULT" | jq -r '.has_correlations')
        
        echo "üéØ Detected strategy: $STRATEGY"
        echo "ü§ñ Models to train: $MODELS_COUNT"
        echo "üòä Has sentiment: $HAS_LABEL"
        echo "üéØ Has importance: $HAS_IMPORTANCE"
        echo "üåê Has correlations: $HAS_CORRELATIONS"
        
        # Exporter les variables
        echo "TRAINING_STRATEGY=$STRATEGY" >> $GITHUB_ENV
        echo "HAS_LABEL=$HAS_LABEL" >> $GITHUB_ENV
        echo "HAS_IMPORTANCE=$HAS_IMPORTANCE" >> $GITHUB_ENV
        echo "HAS_CORRELATIONS=$HAS_CORRELATIONS" >> $GITHUB_ENV
        echo "training-strategy=$STRATEGY" >> $GITHUB_OUTPUT
        
        # Cr√©er les r√©pertoires de sortie
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        echo "TIMESTAMP=$TIMESTAMP" >> $GITHUB_ENV

    - name: ü§ñ Train Multi-Model Strategy (FULL FIX)
      id: training
      run: |
        set -euo pipefail
        
        echo "üöÄ Auto-Training Mode - ALL FIXES Applied!"
        echo "üìã Strategy: $TRAINING_STRATEGY"
        echo "üéØ Training Mode: $TRAINING_MODE"
        
        # üîß CORRECTION CRITIQUE: Mapping TRAINING_MODE ‚Üí EXEC_MODE
        if [ "$TRAINING_MODE" = "test" ]; then
          EXEC_MODE="test"
          echo "üß™ Mode test: pas de push HuggingFace"
        else
          EXEC_MODE="production"
          echo "üöÄ Mode production: push HuggingFace activ√©"
        fi
        
        DATASET_FILE="datasets/$DATASET"
        MODELS_TRAINED=0
        SENTIMENT_UPDATED=false
        IMPORTANCE_UPDATED=false
        CORRELATIONS_UPDATED=false
        
        # Arguments communs avec mapping correct
        COMMON_ARGS="--epochs $EPOCHS --lr $LEARNING_RATE --mode $EXEC_MODE --force-update"
        
        # Entra√Æner le mod√®le de sentiment si disponible
        if [ "$HAS_LABEL" = "true" ]; then
          echo "üòä Training sentiment model..."
          SENTIMENT_OUTPUT="models/sentiment-$TIMESTAMP"
          
          if [ "$TRAINING_MODE" = "incremental" ]; then
            python scripts/finetune.py \
              --dataset "$DATASET_FILE" \
              --target-column label \
              --output_dir "$SENTIMENT_OUTPUT" \
              --incremental \
              --baseline-model "$SENTIMENT_MODEL" \
              --push --hub_id "$SENTIMENT_MODEL" \
              $COMMON_ARGS
          else
            python scripts/finetune.py \
              --dataset "$DATASET_FILE" \
              --target-column label \
              --output_dir "$SENTIMENT_OUTPUT" \
              --model_name "$FALLBACK_MODEL" \
              --push --hub_id "$SENTIMENT_MODEL" \
              $COMMON_ARGS
          fi
          
          MODELS_TRAINED=$((MODELS_TRAINED + 1))
          SENTIMENT_UPDATED=true
          echo "‚úÖ Sentiment model training completed!"
        fi
        
        # Entra√Æner le mod√®le d'importance si disponible
        if [ "$HAS_IMPORTANCE" = "true" ]; then
          echo "üéØ Training importance model..."
          IMPORTANCE_OUTPUT="models/importance-$TIMESTAMP"
          
          if [ "$TRAINING_MODE" = "incremental" ]; then
            python scripts/finetune.py \
              --dataset "$DATASET_FILE" \
              --target-column importance \
              --output_dir "$IMPORTANCE_OUTPUT" \
              --incremental \
              --baseline-model "$IMPORTANCE_MODEL" \
              --push --hub_id "$IMPORTANCE_MODEL" \
              $COMMON_ARGS
          else
            python scripts/finetune.py \
              --dataset "$DATASET_FILE" \
              --target-column importance \
              --output_dir "$IMPORTANCE_OUTPUT" \
              --model_name "$FALLBACK_MODEL" \
              --push --hub_id "$IMPORTANCE_MODEL" \
              $COMMON_ARGS
          fi
          
          MODELS_TRAINED=$((MODELS_TRAINED + 1))
          IMPORTANCE_UPDATED=true
          echo "‚úÖ Importance model training completed!"
        fi
        
        # üåê Entra√Æner le mod√®le de corr√©lations si disponible
        if [ "$HAS_CORRELATIONS" = "true" ]; then
          echo "üåê Training correlations model..."
          CORRELATIONS_OUTPUT="models/correlations-$TIMESTAMP"
          CORRELATIONS_MODEL="Bencode92/tradepulse-finbert-correlations"
          
          if [ "$TRAINING_MODE" = "incremental" ]; then
            python scripts/finetune.py \
              --dataset "$DATASET_FILE" \
              --target-column correlations \
              --output_dir "$CORRELATIONS_OUTPUT" \
              --incremental \
              --baseline-model "$CORRELATIONS_MODEL" \
              --push --hub_id "$CORRELATIONS_MODEL" \
              $COMMON_ARGS
          else
            python scripts/finetune.py \
              --dataset "$DATASET_FILE" \
              --target-column correlations \
              --output_dir "$CORRELATIONS_OUTPUT" \
              --model_name "$FALLBACK_MODEL" \
              --push --hub_id "$CORRELATIONS_MODEL" \
              $COMMON_ARGS
          fi
          
          MODELS_TRAINED=$((MODELS_TRAINED + 1))
          CORRELATIONS_UPDATED=true
          echo "‚úÖ Correlations model training completed!"
        fi
        
        if [ $MODELS_TRAINED -eq 0 ]; then
          echo "‚ùå No valid training columns found"
          exit 1
        fi
        
        # Outputs
        echo "models-trained=$MODELS_TRAINED" >> $GITHUB_OUTPUT
        echo "sentiment-updated=$SENTIMENT_UPDATED" >> $GITHUB_OUTPUT
        echo "importance-updated=$IMPORTANCE_UPDATED" >> $GITHUB_OUTPUT
        echo "correlations-updated=$CORRELATIONS_UPDATED" >> $GITHUB_OUTPUT
        
        echo "üéâ TRAINING COMPLETED: $MODELS_TRAINED models!"

    - name: üìä Final Summary
      if: always()
      run: |
        echo "üöÄ TradePulse ML - ALL FIXES APPLIED"
        echo "===================================="
        echo "‚úÖ PYTHONPATH: ${{ github.workspace }}"
        echo "‚úÖ HF_TOKEN: Available"
        echo "‚úÖ ignore_mismatched_sizes: Applied"
        echo ""
        echo "üîß FIXES APPLIED:"
        echo "  ‚úÖ Job-level PYTHONPATH"
        echo "  ‚úÖ Job-level HF_TOKEN"
        echo "  ‚úÖ Multi-label dimensions fix"
        echo "  ‚úÖ No more os.chdir()"
        echo ""
        if [ "${{ steps.training.outputs.correlations-updated }}" = "true" ]; then
          echo "üåê Correlations Model:"
          echo "  ‚úÖ 125 labels (commodities)"
          echo "  ‚úÖ Multi-label classification"
          echo "  ‚úÖ ignore_mismatched_sizes=True"
        fi

    - name: üì§ Upload Training Artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: training-${{ github.run_id }}
        path: |
          models/**
          training_strategy.json
          pre_training_validation.json
          finetune.log
        retention-days: 30
