name: üîÑ Incremental Training

on:
  schedule:
    - cron: '30 4 * * *'
  
  workflow_dispatch:
    inputs:
      date:
        description: 'Date (YYYY-MM-DD)'
        required: false
        type: string
      replay_size:
        description: 'Replay size'
        required: false
        default: '800'
        type: string
      gate_drop:
        description: 'Max allowed F1 drop'
        required: false
        default: '0.01'
        type: string
      push_to_hub:
        description: 'Push models to HF Hub'
        default: true
        type: boolean

env:
  PYTHON_VERSION: '3.11'
  HF_REPO_SENTIMENT: 'Bencode92/tradepulse-finbert-sentiment'
  HF_REPO_IMPORTANCE: 'Bencode92/tradepulse-finbert-importance'
  HF_TOKEN: ${{ secrets.HF_TOKEN }}

jobs:
  incremental-train:
    name: ü§ñ Incremental Fine-tuning
    runs-on: ubuntu-latest
    
    steps:
      - name: üì• Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: üêç Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: üì¶ Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-ml.txt
          echo "‚úÖ Dependencies installed"

      - name: üìÖ Set date
        id: date
        run: |
          if [ -n "${{ github.event.inputs.date }}" ]; then
            DATE="${{ github.event.inputs.date }}"
          else
            DATE=$(date -u +%F)
          fi
          echo "date=${DATE}" >> $GITHUB_OUTPUT
          echo "Using date: ${DATE}"

      - name: üì∞ Collect daily (if missing)
        env:
          NEWSAPI_KEY: ${{ secrets.NEWSAPI_KEY }}
        run: |
          DAILY_FILE="datasets/daily/${{ steps.date.outputs.date }}.jsonl"
          mkdir -p datasets/daily
          
          if [ ! -f "${DAILY_FILE}" ]; then
            echo "Collecting news for ${{ steps.date.outputs.date }}..."
            
            # Try to collect real news first
            python scripts/collect_news.py --source mixed --count 60 --days 1 --output "${DAILY_FILE}.csv" || true
            
            # Convert CSV to JSONL if it exists
            if [ -f "${DAILY_FILE}.csv" ]; then
              python scripts/convert_to_daily.py "${DAILY_FILE}.csv" --output "${DAILY_FILE}" --date "${{ steps.date.outputs.date }}"
            fi
            
            # If still no file, create minimal test data
            if [ ! -f "${DAILY_FILE}" ]; then
              echo "Creating test data..."
              cat > "${DAILY_FILE}" << 'EOF'
          {"text": "Apple reported strong quarterly earnings beating analyst expectations", "label_sentiment": "positive", "label_importance": "important", "date": "${{ steps.date.outputs.date }}"}
          {"text": "Market volatility increased amid economic uncertainty", "label_sentiment": "negative", "label_importance": "critical", "date": "${{ steps.date.outputs.date }}"}
          {"text": "Oil prices remained stable following OPEC meeting", "label_sentiment": "neutral", "label_importance": "general", "date": "${{ steps.date.outputs.date }}"}
          {"text": "Tech stocks surge as AI investments pay off", "label_sentiment": "positive", "label_importance": "important", "date": "${{ steps.date.outputs.date }}"}
          {"text": "Banking sector faces regulatory challenges", "label_sentiment": "negative", "label_importance": "important", "date": "${{ steps.date.outputs.date }}"}
          EOF
            fi
          else
            echo "Daily file exists: ${DAILY_FILE}"
          fi

      - name: üîÑ Prepare replay
        run: |
          REPLAY_SIZE="${{ github.event.inputs.replay_size }}"
          if [ -z "$REPLAY_SIZE" ]; then REPLAY_SIZE=800; fi
          
          # Create empty history if doesn't exist
          if [ ! -f "datasets/history.jsonl" ]; then
            touch "datasets/history.jsonl"
          fi
          
          python scripts/prepare_replay.py \
            --daily "datasets/daily/${{ steps.date.outputs.date }}.jsonl" \
            --history "datasets/history.jsonl" \
            --out "datasets/combined.jsonl" \
            --replay_size "$REPLAY_SIZE"
          
          echo "‚úÖ Replay buffer prepared"

      - name: üîê HF login
        if: ${{ env.HF_TOKEN != '' && (github.event_name != 'workflow_dispatch' || github.event.inputs.push_to_hub != false) }}
        run: |
          python - <<'PY'
          from huggingface_hub import login
          import os
          t = os.environ.get("HF_TOKEN")
          print("Token present?", bool(t))
          if t: 
              login(token=t)
              print("HF login OK")
          else:
              print("No token, skipping HF login")
          PY

      - name: üéØ Train sentiment (LoRA)
        run: |
          GATE="${{ github.event.inputs.gate_drop }}"
          if [ -z "$GATE" ]; then GATE=0.01; fi
          
          echo "Training sentiment model..."
          
          # Determine if we should push to HF
          if [ "${{ github.event.inputs.push_to_hub }}" = "false" ]; then
            HF_REPO=""
          else
            HF_REPO="${{ env.HF_REPO_SENTIMENT }}"
          fi
          
          python scripts/finetune_incremental.py \
            --task sentiment --incremental \
            --model "yiyanghkust/finbert-tone" \
            --dataset "datasets/combined.jsonl" \
            --output_dir "outputs/incremental" \
            --epochs 2 --batch_size 8 --learning_rate 3e-5 \
            --gate_drop "$GATE" \
            --hf_repo "$HF_REPO" \
            --hf_token "${{ env.HF_TOKEN }}"
          
          echo "‚úÖ Sentiment model complete"

      - name: üìä Train importance (LoRA)
        run: |
          GATE="${{ github.event.inputs.gate_drop }}"
          if [ -z "$GATE" ]; then GATE=0.01; fi
          
          echo "Training importance model..."
          
          # Determine if we should push to HF
          if [ "${{ github.event.inputs.push_to_hub }}" = "false" ]; then
            HF_REPO=""
          else
            HF_REPO="${{ env.HF_REPO_IMPORTANCE }}"
          fi
          
          python scripts/finetune_incremental.py \
            --task importance --incremental \
            --model "distilbert-base-uncased" \
            --dataset "datasets/combined.jsonl" \
            --output_dir "outputs/incremental" \
            --epochs 2 --batch_size 8 --learning_rate 3e-5 \
            --gate_drop "$GATE" \
            --hf_repo "$HF_REPO" \
            --hf_token "${{ env.HF_TOKEN }}"
          
          echo "‚úÖ Importance model complete"

      - name: üíæ Save metrics as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: training-metrics-${{ steps.date.outputs.date }}
          path: |
            outputs/incremental/*/metrics.json
            outputs/last_metrics.json.*
          retention-days: 30

      - name: üìù Commit history updates
        if: success()
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          # Add updated files
          git add datasets/history.jsonl || true
          git add datasets/combined.jsonl || true
          git add datasets/daily/${{ steps.date.outputs.date }}.jsonl || true
          
          # Commit if there are changes
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "chore: update training history for ${{ steps.date.outputs.date }} [skip ci]"
            git push
            echo "‚úÖ History committed"
          fi

      - name: üìä Generate summary
        if: always()
        run: |
          echo "## üìä Training Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Date:** ${{ steps.date.outputs.date }}" >> $GITHUB_STEP_SUMMARY
          echo "**Replay Size:** ${{ github.event.inputs.replay_size || '800' }}" >> $GITHUB_STEP_SUMMARY
          echo "**Gate Drop:** ${{ github.event.inputs.gate_drop || '0.01' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "outputs/last_metrics.json.sentiment" ]; then
            echo "### Sentiment Model" >> $GITHUB_STEP_SUMMARY
            python -c "
          import json
          with open('outputs/last_metrics.json.sentiment') as f:
              data = json.load(f)
              print(f'**F1 Score:** {data.get(\"f1_macro\", 0):.4f}')
            " >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ -f "outputs/last_metrics.json.importance" ]; then
            echo "### Importance Model" >> $GITHUB_STEP_SUMMARY
            python -c "
          import json
          with open('outputs/last_metrics.json.importance') as f:
              data = json.load(f)
              print(f'**F1 Score:** {data.get(\"f1_macro\", 0):.4f}')
            " >> $GITHUB_STEP_SUMMARY
          fi

  notify:
    name: üìß Notify Results
    needs: incremental-train
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: üìß Send notification
        if: failure()
        run: |
          echo "‚ö†Ô∏è Incremental training failed! Check the logs for details."
          # Add your notification logic here (Slack, email, etc.)
