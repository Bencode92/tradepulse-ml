# ü§ñ TradePulse ML - FinBERT Fine-tuning

Repository priv√© pour le fine-tuning de mod√®les FinBERT pour l'analyse de sentiment financier de TradePulse avec **validation automatique des datasets**.

## üöÄ Utilisation rapide

### 1. Via GitHub Actions (Recommand√©)

1. **Pr√©parez votre dataset** dans le dossier `datasets/`
2. **Validation automatique** : Le syst√®me v√©rifie la qualit√© de vos donn√©es
3. Allez dans l'onglet **Actions** de ce repository
4. S√©lectionnez "ü§ñ TradePulse FinBERT Fine-tuning"
5. Cliquez "Run workflow" et configurez :
   - **Dataset**: `auto-latest` (dernier dataset) ou nom sp√©cifique
   - **Model**: `yiyanghkust/finbert-tone`
   - **Epochs**: `3`
   - **Learning rate**: `2e-5`
   - **Push to HuggingFace**: `true/false`

### 2. Workflow Pull Request (Nouveaut√© üî•)

```bash
# 1. Cr√©er une branche pour votre dataset
git checkout -b feature/dataset-20250706

# 2. Ajouter votre dataset
cp mon_dataset.csv datasets/financial_news_20250706.csv
git add datasets/financial_news_20250706.csv
git commit -m "Add Q4 financial news dataset"
git push origin feature/dataset-20250706

# 3. Cr√©er une Pull Request
# ‚Üí Validation automatique + rapport de qualit√©
# ‚Üí Commentaire auto sur la PR avec r√©sultats
# ‚Üí Merge = d√©clenchement automatique du fine-tuning
```

### 3. En local

```bash
# Cloner le repository
git clone https://github.com/Bencode92/tradepulse-ml.git
cd tradepulse-ml

# Installer les d√©pendances
pip install -r requirements.txt

# Valider votre dataset (NOUVEAU)
python scripts/validate_dataset.py datasets/mon_dataset.csv

# Lancer le fine-tuning
python scripts/finetune.py \
    --dataset datasets/mon_dataset.csv \
    --output_dir models/finbert-v1 \
    --epochs 3 \
    --lr 2e-5
```

## üìÅ Structure du repository

```
tradepulse-ml/
‚îú‚îÄ‚îÄ üìÅ .github/workflows/          # GitHub Actions
‚îÇ   ‚îú‚îÄ‚îÄ finetune-model.yml         # Workflow de fine-tuning (am√©lior√©)
‚îÇ   ‚îî‚îÄ‚îÄ dataset-quality-gate.yml   # Validation des datasets (NOUVEAU)
‚îú‚îÄ‚îÄ üìÅ datasets/                   # Datasets d'entra√Ænement
‚îÇ   ‚îú‚îÄ‚îÄ news_20250705.csv          # Exemple dataset (15 √©chantillons)
‚îÇ   ‚îú‚îÄ‚îÄ financial_news_20250706.csv # Dataset test (20 √©chantillons)
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ raw/                    # Donn√©es brutes
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ labeled/                # Donn√©es √©tiquet√©es
‚îú‚îÄ‚îÄ üìÅ models/                     # Mod√®les entra√Æn√©s (g√©n√©r√©)
‚îú‚îÄ‚îÄ üìÅ scripts/                    # Scripts Python
‚îÇ   ‚îú‚îÄ‚îÄ finetune.py                # Script principal de fine-tuning
‚îÇ   ‚îî‚îÄ‚îÄ validate_dataset.py        # Validation datasets (NOUVEAU)
‚îú‚îÄ‚îÄ requirements.txt               # D√©pendances Python
‚îú‚îÄ‚îÄ DATASET_WORKFLOW.md           # Guide validation (NOUVEAU)
‚îî‚îÄ‚îÄ README.md                     # Ce fichier
```

## üîç Validation automatique des datasets (NOUVEAU !)

Le syst√®me valide automatiquement vos datasets pour garantir la qualit√© :

### ‚úÖ V√©rifications automatiques
- **Structure** : Colonnes `text` et `label` requises
- **Labels** : Seulement `positive`, `negative`, `neutral`
- **Qualit√©** : D√©tection doublons, textes vides, longueur
- **Distribution** : √âquilibrage des classes
- **Format** : CSV et JSON support√©s

### üìä Rapport de validation
```
üîç RAPPORT DE VALIDATION DATASET
==================================================

üìä STATISTIQUES:
  Total √©chantillons: 20
  Longueur moyenne: 156.4 caract√®res
  Doublons: 0

üìà DISTRIBUTION DES LABELS:
  positive: 8 (40.0%)
  negative: 6 (30.0%)  
  neutral: 6 (30.0%)

‚úÖ VALIDATION R√âUSSIE
```

## üìä Format des datasets

### Format CSV (Recommand√©)
```csv
text,label
"Apple reported strong earnings beating expectations...",positive
"Market volatility increased amid economic uncertainty...",negative
"Oil prices remained stable following OPEC meeting...",neutral
```

### Format JSON
```json
[
  {
    "text": "Apple reported strong earnings...",
    "label": "positive"
  },
  {
    "text": "Market volatility increased...",
    "label": "negative"
  }
]
```

### üìè Crit√®res de qualit√©
- **Labels valides** : `positive`, `negative`, `neutral` uniquement
- **Longueur texte** : 20-512 caract√®res recommand√©s
- **Pas de doublons** dans les textes
- **Distribution √©quilibr√©e** : √âviter >70% d'une seule classe
- **Minimum** : 10 √©chantillons (50+ recommand√©)

## ü§ñ Workflows automatis√©s

### 1. Dataset Quality Gate
- **D√©clenchement** : Pull Request touchant `datasets/`
- **Validation** : Structure, contenu, distribution
- **Rapport** : Commentaire automatique sur PR
- **Blocage** : Emp√™che merge si validation √©choue

### 2. Smart Fine-tuning
- **S√©lection auto** : Dernier dataset valid√©
- **D√©clenchement** : Push sur `datasets/` apr√®s validation
- **Configuration** : Param√®tres optimis√©s par d√©faut
- **Artifacts** : Mod√®les et logs automatiquement sauv√©s

## ‚öôÔ∏è Configuration

### Variables d'environnement (GitHub Secrets)

Pour utiliser les fonctionnalit√©s avanc√©es, configurez ces secrets dans **Settings > Secrets**:

- `HF_TOKEN`: Token HuggingFace (obligatoire pour push de mod√®les)
- `WANDB_API_KEY`: Token Weights & Biases (optionnel)

### Arguments du script de validation

```bash
python scripts/validate_dataset.py --help
```

| Argument | Description | D√©faut |
|----------|-------------|---------|
| `dataset_path` | Chemin vers le CSV/JSON | **Requis** |
| `--max-length` | Longueur max des textes | `512` |
| `--min-samples` | √âchantillons minimum | `10` |
| `--quiet` | Mode silencieux | `False` |

### Arguments du script de fine-tuning

| Argument | Description | D√©faut |
|----------|-------------|---------|
| `--dataset` | Chemin vers le dataset | **Requis** |
| `--output_dir` | R√©pertoire de sortie | **Requis** |
| `--model_name` | Mod√®le de base | `yiyanghkust/finbert-tone` |
| `--epochs` | Nombre d'√©poques | `3` |
| `--lr` | Taux d'apprentissage | `2e-5` |
| `--train_bs` | Batch size train | `16` |
| `--eval_bs` | Batch size eval | `32` |
| `--push` | Push vers HF Hub | `False` |
| `--hub_id` | ID du repo HF | `None` |

## üìà Monitoring & MLOps

### Logs d'entra√Ænement
- **TensorBoard**: `models/[model_name]/logs/`
- **Fichiers log**: `finetune.log`
- **Rapport**: `models/[model_name]/training_report.json`

### GitHub Actions
- **Artifacts** : Mod√®les et logs t√©l√©chargeables
- **Notifications** : Statut des jobs par email
- **History** : Historique complet des entra√Ænements

### M√©triques g√©n√©r√©es
- **Accuracy**: Pr√©cision globale
- **F1-Score**: Score F1 pond√©r√©
- **Precision**: Pr√©cision par classe
- **Recall**: Rappel par classe

## üîß Mod√®les support√©s

- `yiyanghkust/finbert-tone` (Recommand√©)
- `ProsusAI/finbert`
- `nlptown/bert-base-multilingual-uncased-sentiment`

## üìù Exemple d'utilisation compl√®te

### 1. Pr√©parer un dataset

```python
import pandas as pd

# Cr√©er un dataset depuis vos donn√©es TradePulse
data = [
    {"text": "Tesla stock surged after earnings beat expectations", "label": "positive"},
    {"text": "Market correction continues amid economic uncertainty", "label": "negative"},
    {"text": "Oil prices stable following OPEC+ meeting decision", "label": "neutral"}
]

df = pd.DataFrame(data)
df.to_csv("datasets/my_dataset_20250706.csv", index=False)
```

### 2. Valider le dataset

```bash
# Validation locale
python scripts/validate_dataset.py datasets/my_dataset_20250706.csv

# Ou via GitHub Actions (manuel)
# Actions ‚Üí Dataset Quality Gate ‚Üí Run workflow
```

### 3. Fine-tuning automatique

```bash
# Option A: Push direct (validation + training auto)
git add datasets/my_dataset_20250706.csv
git commit -m "Add validated dataset for training"
git push origin main

# Option B: Via Pull Request (recommand√©)
git checkout -b feature/dataset-20250706
git add datasets/my_dataset_20250706.csv
git commit -m "Add comprehensive dataset for Q4"
git push origin feature/dataset-20250706
# ‚Üí Cr√©er PR ‚Üí Validation ‚Üí Merge ‚Üí Training auto
```

### 4. Utiliser le mod√®le entra√Æn√©

```python
from transformers import pipeline

# Charger le mod√®le fine-tun√©
classifier = pipeline(
    "text-classification",
    model="models/finbert-20250706_143022",  # Dossier g√©n√©r√©
    tokenizer="models/finbert-20250706_143022"
)

# Analyser un texte
result = classifier("Apple reported strong quarterly results")
print(result)
# [{'label': 'positive', 'score': 0.95}]
```

## üö® D√©pannage

### Erreurs de validation

```bash
# Voir les d√©tails
python scripts/validate_dataset.py datasets/problematic.csv

# Erreurs communes et solutions :
# ‚ùå "Labels invalides" ‚Üí Utiliser positive/negative/neutral
# ‚ùå "Colonnes incorrectes" ‚Üí Renommer en text,label  
# ‚ùå "Textes manquants" ‚Üí Supprimer lignes vides
# ‚ö†Ô∏è "Classe d√©s√©quilibr√©e" ‚Üí Ajouter √©chantillons minoritaires
```

### Workflow GitHub Actions

1. **Dataset validation failed**
   - Consulter les logs dans Actions ‚Üí Dataset Quality Gate
   - Corriger les erreurs selon le rapport
   - Re-push pour relancer la validation

2. **Training not triggered**
   - V√©rifier que la validation a r√©ussi
   - S'assurer que le fichier est dans `datasets/` (pas sous-dossier)
   - V√©rifier les logs Actions ‚Üí TradePulse FinBERT Fine-tuning

### Logs utiles

```bash
# Logs locaux
tail -f finetune.log

# TensorBoard
tensorboard --logdir models/[model_name]/logs/

# GitHub Actions
# Actions ‚Üí [Workflow] ‚Üí [Run] ‚Üí [Job] ‚Üí Logs d√©taill√©s
```

## üìö Documentation d√©taill√©e

- **[DATASET_WORKFLOW.md](DATASET_WORKFLOW.md)** : Guide complet du workflow de validation
- **Validation locale** : `python scripts/validate_dataset.py --help`
- **Fine-tuning** : `python scripts/finetune.py --help`

## üîÑ Int√©gration avec TradePulse

Le mod√®le fine-tun√© peut √™tre int√©gr√© dans le syst√®me principal :

1. **Push vers HuggingFace Hub** avec `--push --hub_id`
2. **Configurer le mod√®le custom** dans `fmp_news_updater.py`:
   ```python
   _FINBERT_MODEL = "Bencode92/tradepulse-finbert-custom"
   USE_CUSTOM_FINBERT = True
   ```

## üéØ Prochaines √©tapes

- [ ] Int√©gration WANDB pour tracking avanc√©
- [ ] Tests A/B automatiques entre mod√®les  
- [ ] Pipeline de data augmentation
- [ ] Interface web pour annotation
- [ ] Monitoring de drift des donn√©es

## üìû Support

Pour toute question ou probl√®me :
- üêõ **Issues** : Ouvrir une issue dans ce repository
- üìã **Logs** : Consulter Actions ‚Üí Job logs
- üìñ **Documentation** : DATASET_WORKFLOW.md + ce README
- üîç **Validation** : `python scripts/validate_dataset.py --help`

---

**TradePulse ML** - Fine-tuning FinBERT avec validation automatique pour l'analyse de sentiment financier üöÄ‚ú®

*Nouveau : Dataset Quality Gate pour des mod√®les plus fiables !*
