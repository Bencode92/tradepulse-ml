# ğŸ¤– TradePulse ML - FinBERT Fine-tuning

Repository privÃ© pour le fine-tuning de modÃ¨les FinBERT pour l'analyse de sentiment financier de TradePulse avec **validation automatique des datasets**.

## ğŸš€ Utilisation rapide

### 1. Via GitHub Actions (RecommandÃ©)

1. **PrÃ©parez votre dataset** dans le dossier `datasets/`
2. **Validation automatique** : Le systÃ¨me vÃ©rifie la qualitÃ© de vos donnÃ©es
3. Allez dans l'onglet **Actions** de ce repository
4. SÃ©lectionnez "ğŸ¤– TradePulse FinBERT Fine-tuning"
5. Cliquez "Run workflow" et configurez :
   - **Dataset**: `auto-latest` (dernier dataset) ou nom spÃ©cifique
   - **Model**: `yiyanghkust/finbert-tone`
   - **Epochs**: `3`
   - **Learning rate**: `2e-5`
   - **Push to HuggingFace**: `true/false`

### 2. Workflow Pull Request (NouveautÃ© ğŸ”¥)

```bash
# 1. CrÃ©er une branche pour votre dataset
git checkout -b feature/dataset-20250706

# 2. Ajouter votre dataset
cp mon_dataset.csv datasets/financial_news_20250706.csv
git add datasets/financial_news_20250706.csv
git commit -m "Add Q4 financial news dataset"
git push origin feature/dataset-20250706

# 3. CrÃ©er une Pull Request
# â†’ Validation automatique + rapport de qualitÃ©
# â†’ Commentaire auto sur la PR avec rÃ©sultats
# â†’ Merge = dÃ©clenchement automatique du fine-tuning
```

### 3. En local

```bash
# Cloner le repository
git clone https://github.com/Bencode92/tradepulse-ml.git
cd tradepulse-ml

# Installer les dÃ©pendances
pip install -r requirements.txt

# Valider votre dataset (NOUVEAU)
python scripts/validate_dataset.py datasets/mon_dataset.csv

# Lancer le fine-tuning
python scripts/finetune.py \
    --dataset datasets/mon_dataset.csv \
    --output_dir models/finbert-v1 \
    --epochs 3 \
    --lr 2e-5
```

## ğŸ“ Structure du repository

```
tradepulse-ml/
â”œâ”€â”€ ğŸ“ .github/workflows/          # GitHub Actions
â”‚   â”œâ”€â”€ finetune-model.yml         # Workflow de fine-tuning (amÃ©liorÃ©)
â”‚   â””â”€â”€ dataset-quality-gate.yml   # Validation des datasets (NOUVEAU)
â”œâ”€â”€ ğŸ“ datasets/                   # Datasets d'entraÃ®nement
â”‚   â”œâ”€â”€ news_20250705.csv          # Exemple dataset (15 Ã©chantillons)
â”‚   â”œâ”€â”€ financial_news_20250706.csv # Dataset test (20 Ã©chantillons)
â”‚   â”œâ”€â”€ ğŸ“ raw/                    # DonnÃ©es brutes
â”‚   â””â”€â”€ ğŸ“ labeled/                # DonnÃ©es Ã©tiquetÃ©es
â”œâ”€â”€ ğŸ“ models/                     # ModÃ¨les entraÃ®nÃ©s (gÃ©nÃ©rÃ©)
â”œâ”€â”€ ğŸ“ scripts/                    # Scripts Python
â”‚   â”œâ”€â”€ finetune.py                # Script principal de fine-tuning
â”‚   â””â”€â”€ validate_dataset.py        # Validation datasets (NOUVEAU)
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â”œâ”€â”€ DATASET_WORKFLOW.md           # Guide validation (NOUVEAU)
â””â”€â”€ README.md                     # Ce fichier
```

## ğŸ” Validation automatique des datasets (NOUVEAU !)

Le systÃ¨me valide automatiquement vos datasets pour garantir la qualitÃ© :

### âœ… VÃ©rifications automatiques
- **Structure** : Colonnes `text` et `label` requises
- **Labels** : Seulement `positive`, `negative`, `neutral`
- **QualitÃ©** : DÃ©tection doublons, textes vides, longueur
- **Distribution** : Ã‰quilibrage des classes
- **Format** : CSV et JSON supportÃ©s

### ğŸ“Š Rapport de validation
```
ğŸ” RAPPORT DE VALIDATION DATASET
==================================================

ğŸ“Š STATISTIQUES:
  Total Ã©chantillons: 20
  Longueur moyenne: 156.4 caractÃ¨res
  Doublons: 0

ğŸ“ˆ DISTRIBUTION DES LABELS:
  positive: 8 (40.0%)
  negative: 6 (30.0%)  
  neutral: 6 (30.0%)

âœ… VALIDATION RÃ‰USSIE
```

## ğŸ“Š Format des datasets

### Format CSV (RecommandÃ©)
```csv
text,label
"Apple reported strong earnings beating expectations...",positive
"Market volatility increased amid economic uncertainty...",negative
"Oil prices remained stable following OPEC meeting...",neutral
```

### Format JSON
```json
[
  {
    "text": "Apple reported strong earnings...",
    "label": "positive"
  },
  {
    "text": "Market volatility increased...",
    "label": "negative"
  }
]
```

### ğŸ“ CritÃ¨res de qualitÃ©
- **Labels valides** : `positive`, `negative`, `neutral` uniquement
- **Longueur texte** : 20-512 caractÃ¨res recommandÃ©s
- **Pas de doublons** dans les textes
- **Distribution Ã©quilibrÃ©e** : Ã‰viter >70% d'une seule classe
- **Minimum** : 10 Ã©chantillons (50+ recommandÃ©)

## ğŸ¤– Workflows automatisÃ©s

### 1. Dataset Quality Gate
- **DÃ©clenchement** : Pull Request touchant `datasets/`
- **Validation** : Structure, contenu, distribution
- **Rapport** : Commentaire automatique sur PR
- **Blocage** : EmpÃªche merge si validation Ã©choue

### 2. Smart Fine-tuning
- **SÃ©lection auto** : Dernier dataset validÃ©
- **DÃ©clenchement** : Push sur `datasets/` aprÃ¨s validation
- **Configuration** : ParamÃ¨tres optimisÃ©s par dÃ©faut
- **Artifacts** : ModÃ¨les et logs automatiquement sauvÃ©s

## âš™ï¸ Configuration

### Variables d'environnement (GitHub Secrets)

Pour utiliser les fonctionnalitÃ©s avancÃ©es, configurez ces secrets dans **Settings > Secrets**:

- `HF_TOKEN`: Token HuggingFace (obligatoire pour push de modÃ¨les)
- `WANDB_API_KEY`: Token Weights & Biases (optionnel)

### Arguments du script de validation

```bash
python scripts/validate_dataset.py --help
```

| Argument | Description | DÃ©faut |
|----------|-------------|---------|
| `dataset_path` | Chemin vers le CSV/JSON | **Requis** |
| `--max-length` | Longueur max des textes | `512` |
| `--min-samples` | Ã‰chantillons minimum | `10` |
| `--quiet` | Mode silencieux | `False` |

### Arguments du script de fine-tuning

| Argument | Description | DÃ©faut |
|----------|-------------|---------|
| `--dataset` | Chemin vers le dataset | **Requis** |
| `--output_dir` | RÃ©pertoire de sortie | **Requis** |
| `--model_name` | ModÃ¨le de base | `yiyanghkust/finbert-tone` |
| `--epochs` | Nombre d'Ã©poques | `3` |
| `--lr` | Taux d'apprentissage | `2e-5` |
| `--train_bs` | Batch size train | `16` |
| `--eval_bs` | Batch size eval | `32` |
| `--push` | Push vers HF Hub | `False` |
| `--hub_id` | ID du repo HF | `None` |

## ğŸ“ˆ Monitoring & MLOps

### Logs d'entraÃ®nement
- **TensorBoard**: `models/[model_name]/logs/`
- **Fichiers log**: `finetune.log`
- **Rapport**: `models/[model_name]/training_report.json`

### GitHub Actions
- **Artifacts** : ModÃ¨les et logs tÃ©lÃ©chargeables
- **Notifications** : Statut des jobs par email
- **History** : Historique complet des entraÃ®nements

### MÃ©triques gÃ©nÃ©rÃ©es
- **Accuracy**: PrÃ©cision globale
- **F1-Score**: Score F1 pondÃ©rÃ©
- **Precision**: PrÃ©cision par classe
- **Recall**: Rappel par classe

## ğŸ”§ ModÃ¨les supportÃ©s

- `yiyanghkust/finbert-tone` (RecommandÃ©)
- `ProsusAI/finbert`
- `nlptown/bert-base-multilingual-uncased-sentiment`

## ğŸ“ Exemple d'utilisation complÃ¨te

### 1. PrÃ©parer un dataset

```python
import pandas as pd

# CrÃ©er un dataset depuis vos donnÃ©es TradePulse
data = [
    {"text": "Tesla stock surged after earnings beat expectations", "label": "positive"},
    {"text": "Market correction continues amid economic uncertainty", "label": "negative"},
    {"text": "Oil prices stable following OPEC+ meeting decision", "label": "neutral"}
]

df = pd.DataFrame(data)
df.to_csv("datasets/my_dataset_20250706.csv", index=False)
```

### 2. Valider le dataset

```bash
# Validation locale
python scripts/validate_dataset.py datasets/my_dataset_20250706.csv

# Ou via GitHub Actions (manuel)
# Actions â†’ Dataset Quality Gate â†’ Run workflow
```

### 3. Fine-tuning automatique

```bash
# Option A: Push direct (validation + training auto)
git add datasets/my_dataset_20250706.csv
git commit -m "Add validated dataset for training"
git push origin main

# Option B: Via Pull Request (recommandÃ©)
git checkout -b feature/dataset-20250706
git add datasets/my_dataset_20250706.csv
git commit -m "Add comprehensive dataset for Q4"
git push origin feature/dataset-20250706
# â†’ CrÃ©er PR â†’ Validation â†’ Merge â†’ Training auto
```

### 4. Utiliser le modÃ¨le entraÃ®nÃ©

```python
from transformers import pipeline

# Charger le modÃ¨le fine-tunÃ©
classifier = pipeline(
    "text-classification",
    model="models/finbert-20250706_143022",  # Dossier gÃ©nÃ©rÃ©
    tokenizer="models/finbert-20250706_143022"
)

# Analyser un texte
result = classifier("Apple reported strong quarterly results")
print(result)
# [{'label': 'positive', 'score': 0.95}]
```

## ğŸš¨ DÃ©pannage

### Erreurs de validation

```bash
# Voir les dÃ©tails
python scripts/validate_dataset.py datasets/problematic.csv

# Erreurs communes et solutions :
# âŒ "Labels invalides" â†’ Utiliser positive/negative/neutral
# âŒ "Colonnes incorrectes" â†’ Renommer en text,label  
# âŒ "Textes manquants" â†’ Supprimer lignes vides
# âš ï¸ "Classe dÃ©sÃ©quilibrÃ©e" â†’ Ajouter Ã©chantillons minoritaires
```

### Workflow GitHub Actions

1. **Dataset validation failed**
   - Consulter les logs dans Actions â†’ Dataset Quality Gate
   - Corriger les erreurs selon le rapport
   - Re-push pour relancer la validation

2. **Training not triggered**
   - VÃ©rifier que la validation a rÃ©ussi
   - S'assurer que le fichier est dans `datasets/` (pas sous-dossier)
   - VÃ©rifier les logs Actions â†’ TradePulse FinBERT Fine-tuning

### Logs utiles

```bash
# Logs locaux
tail -f finetune.log

# TensorBoard
tensorboard --logdir models/[model_name]/logs/

# GitHub Actions
# Actions â†’ [Workflow] â†’ [Run] â†’ [Job] â†’ Logs dÃ©taillÃ©s
```

## ğŸ“š Documentation dÃ©taillÃ©e

- **[DATASET_WORKFLOW.md](DATASET_WORKFLOW.md)** : Guide complet du workflow de validation
- **Validation locale** : `python scripts/validate_dataset.py --help`
- **Fine-tuning** : `python scripts/finetune.py --help`

## ğŸ”„ IntÃ©gration avec TradePulse

Le modÃ¨le fine-tunÃ© peut Ãªtre intÃ©grÃ© dans le systÃ¨me principal :

1. **Push vers HuggingFace Hub** avec `--push --hub_id`
2. **Configurer le modÃ¨le custom** dans `fmp_news_updater.py`:
   ```python
   _FINBERT_MODEL = "Bencode92/tradepulse-finbert-custom"
   USE_CUSTOM_FINBERT = True
   ```

## ğŸ¯ Prochaines Ã©tapes

- [ ] IntÃ©gration WANDB pour tracking avancÃ©
- [ ] Tests A/B automatiques entre modÃ¨les  
- [ ] Pipeline de data augmentation
- [ ] Interface web pour annotation
- [ ] Monitoring de drift des donnÃ©es

## ğŸ“ Support

Pour toute question ou problÃ¨me :
- ğŸ› **Issues** : Ouvrir une issue dans ce repository
- ğŸ“‹ **Logs** : Consulter Actions â†’ Job logs
- ğŸ“– **Documentation** : DATASET_WORKFLOW.md + ce README
- ğŸ” **Validation** : `python scripts/validate_dataset.py --help`

---

**TradePulse ML** - Fine-tuning FinBERT avec validation automatique pour l'analyse de sentiment financier ğŸš€âœ¨

*Nouveau : Dataset Quality Gate pour des modÃ¨les plus fiables !*
