# ü§ñ TradePulse ML - FinBERT Fine-tuning

Repository priv√© pour le fine-tuning de mod√®les FinBERT pour l'analyse de sentiment financier de TradePulse.

## üöÄ Utilisation rapide

### 1. Via GitHub Actions (Recommand√©)

1. **Pr√©parez votre dataset** dans le dossier `datasets/`
2. Allez dans l'onglet **Actions** de ce repository
3. S√©lectionnez "ü§ñ TradePulse FinBERT Fine-tuning"
4. Cliquez "Run workflow" et configurez :
   - **Dataset**: `news_20250705.csv` (ou votre fichier)
   - **Model**: `yiyanghkust/finbert-tone`
   - **Epochs**: `3`
   - **Learning rate**: `2e-5`
   - **Push to HuggingFace**: `true/false`

### 2. En local

```bash
# Cloner le repository
git clone https://github.com/Bencode92/tradepulse-ml.git
cd tradepulse-ml

# Installer les d√©pendances
pip install -r requirements.txt

# Lancer le fine-tuning
python scripts/finetune.py \
    --dataset datasets/news_20250705.csv \
    --output_dir models/finbert-v1 \
    --epochs 3 \
    --lr 2e-5
```

## üìÅ Structure du repository

```
tradepulse-ml/
‚îú‚îÄ‚îÄ üìÅ .github/workflows/    # GitHub Actions
‚îÇ   ‚îî‚îÄ‚îÄ finetune-model.yml   # Workflow de fine-tuning
‚îú‚îÄ‚îÄ üìÅ datasets/             # Datasets d'entra√Ænement
‚îÇ   ‚îî‚îÄ‚îÄ news_20250705.csv    # Exemple de dataset
‚îú‚îÄ‚îÄ üìÅ models/               # Mod√®les entra√Æn√©s (g√©n√©r√©)
‚îú‚îÄ‚îÄ üìÅ scripts/              # Scripts Python
‚îÇ   ‚îî‚îÄ‚îÄ finetune.py          # Script principal de fine-tuning
‚îú‚îÄ‚îÄ requirements.txt         # D√©pendances Python
‚îî‚îÄ‚îÄ README.md               # Ce fichier
```

## üìä Format des datasets

### Format CSV
```csv
text,label
"Apple reported strong earnings...",positive
"Market volatility increased...",negative
"Oil prices remained stable...",neutral
```

### Format JSON
```json
[
  {
    "text": "Apple reported strong earnings...",
    "label": "positive"
  },
  {
    "text": "Market volatility increased...",
    "label": "negative"
  }
]
```

## ‚öôÔ∏è Configuration

### Variables d'environnement (GitHub Secrets)

Pour utiliser les fonctionnalit√©s avanc√©es, configurez ces secrets dans **Settings > Secrets**:

- `HF_TOKEN`: Token HuggingFace (obligatoire pour push de mod√®les)
- `WANDB_API_KEY`: Token Weights & Biases (optionnel)

### Arguments du script

```bash
python scripts/finetune.py --help
```

| Argument | Description | D√©faut |
|----------|-------------|---------|
| `--dataset` | Chemin vers le dataset | **Requis** |
| `--output_dir` | R√©pertoire de sortie | **Requis** |
| `--model_name` | Mod√®le de base | `yiyanghkust/finbert-tone` |
| `--epochs` | Nombre d'√©poques | `3` |
| `--lr` | Taux d'apprentissage | `2e-5` |
| `--train_bs` | Batch size train | `16` |
| `--eval_bs` | Batch size eval | `32` |
| `--push` | Push vers HF Hub | `False` |
| `--hub_id` | ID du repo HF | `None` |

## üìà Monitoring

### Logs d'entra√Ænement
- **TensorBoard**: `models/[model_name]/logs/`
- **Fichiers log**: `finetune.log`
- **Rapport**: `models/[model_name]/training_report.json`

### M√©triques g√©n√©r√©es
- **Accuracy**: Pr√©cision globale
- **F1-Score**: Score F1 pond√©r√©
- **Precision**: Pr√©cision par classe
- **Recall**: Rappel par classe

## üîß Mod√®les support√©s

- `yiyanghkust/finbert-tone` (Recommand√©)
- `ProsusAI/finbert`
- `nlptown/bert-base-multilingual-uncased-sentiment`

## üìù Exemple d'utilisation

### 1. Pr√©parer un dataset personnalis√©

```python
import pandas as pd

# Cr√©er un dataset depuis vos donn√©es TradePulse
data = [
    {"text": "Tesla stock surged after earnings beat", "label": "positive"},
    {"text": "Market correction continues amid uncertainty", "label": "negative"},
    {"text": "Oil prices stable following OPEC meeting", "label": "neutral"}
]

df = pd.DataFrame(data)
df.to_csv("datasets/my_dataset.csv", index=False)
```

### 2. Lancer le fine-tuning

```bash
python scripts/finetune.py \
    --dataset datasets/my_dataset.csv \
    --output_dir models/tradepulse-custom \
    --epochs 5 \
    --lr 1e-5 \
    --push \
    --hub_id Bencode92/tradepulse-finbert-custom
```

### 3. Utiliser le mod√®le entra√Æn√©

```python
from transformers import pipeline

# Charger le mod√®le fine-tun√©
classifier = pipeline(
    "text-classification",
    model="models/tradepulse-custom",
    tokenizer="models/tradepulse-custom"
)

# Analyser un texte
result = classifier("Apple reported strong quarterly results")
print(result)
# [{'label': 'positive', 'score': 0.95}]
```

## üö® D√©pannage

### Erreurs communes

1. **"Dataset file not found"**
   - V√©rifiez que le fichier existe dans `datasets/`
   - Utilisez le nom exact du fichier

2. **"HF_TOKEN required"**
   - Configurez le secret `HF_TOKEN` dans GitHub
   - Ou d√©sactivez `push_to_hub`

3. **"Out of memory"**
   - R√©duisez `train_bs` et `eval_bs`
   - R√©duisez `max_length`

### Logs utiles

```bash
# Voir les logs d'entra√Ænement
tail -f finetune.log

# V√©rifier TensorBoard
tensorboard --logdir models/[model_name]/logs/
```

## üîÑ Int√©gration avec TradePulse

Le mod√®le fine-tun√© peut √™tre int√©gr√© dans le syst√®me principal :

1. **Push vers HuggingFace Hub** avec `--push --hub_id`
2. **Configurer le mod√®le custom** dans `fmp_news_updater.py`:
   ```python
   _FINBERT_MODEL = "Bencode92/tradepulse-finbert-custom"
   USE_CUSTOM_FINBERT = True
   ```

## üìû Support

Pour toute question ou probl√®me :
- Ouvrir une issue dans ce repository
- V√©rifier les logs d'Actions GitHub
- Consulter la documentation HuggingFace Transformers

---

**TradePulse ML** - Fine-tuning FinBERT pour l'analyse de sentiment financier üöÄ
